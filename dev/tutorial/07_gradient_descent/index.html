
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://jaxleyverse.github.io/jaxley/dev/tutorial/07_gradient_descent/">
      
      
        <link rel="prev" href="../08_importing_morphologies/">
      
      
        <link rel="next" href="../../install/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.9">
    
    
      
        <title>Training models - Jaxley</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.4af4bdda.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#training-biophysical-models" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Jaxley" class="md-header__button md-logo" aria-label="Jaxley" data-md-component="logo">
      
  <img src="../../logo_white.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Jaxley
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Training models
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="http://github.com/jaxleyverse/jaxley" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    jaxleyverse/jaxley
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Jaxley" class="md-nav__button md-logo" aria-label="Jaxley" data-md-component="logo">
      
  <img src="../../logo_white.png" alt="logo">

    </a>
    Jaxley
  </label>
  
    <div class="md-nav__source">
      <a href="http://github.com/jaxleyverse/jaxley" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    jaxleyverse/jaxley
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Tutorials
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01_morph_neurons/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting started
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../02_small_network/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Run a network simulation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03_setting_parameters.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Set parameters
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../04_jit_and_vmap/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Accelerate simulations
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../05_channel_and_synapse_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Define your own channels
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../06_groups/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Define groups
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../08_importing_morphologies/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Read and handle SWC files
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Training models
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Training models
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#defining-a-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Defining a dataset
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#defining-trainable-parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Defining trainable parameters
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#making-synaptic-parameters-trainable" class="md-nav__link">
    <span class="md-ellipsis">
      Making synaptic parameters trainable
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#running-the-simulation" class="md-nav__link">
    <span class="md-ellipsis">
      Running the simulation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stimulating-the-network" class="md-nav__link">
    <span class="md-ellipsis">
      Stimulating the network
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#defining-a-loss-function" class="md-nav__link">
    <span class="md-ellipsis">
      Defining a loss function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#defining-parameter-transformations" class="md-nav__link">
    <span class="md-ellipsis">
      Defining parameter transformations
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#using-checkpointing" class="md-nav__link">
    <span class="md-ellipsis">
      Using checkpointing
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training" class="md-nav__link">
    <span class="md-ellipsis">
      Training
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#writing-a-dataloader" class="md-nav__link">
    <span class="md-ellipsis">
      Writing a dataloader
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-loop" class="md-nav__link">
    <span class="md-ellipsis">
      Training loop
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../install/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Installation
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Contributing
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Contributing
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../contribute/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Guide
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../code_of_conduct/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Code of Conduct
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    API Reference
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/modules/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Modules
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/integration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Simulation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/mechanisms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Mechansims
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/connect/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Connecting Cells
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/optimize/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Utils
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../faq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FAQ
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../credits/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Credits
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#defining-a-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Defining a dataset
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#defining-trainable-parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Defining trainable parameters
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#making-synaptic-parameters-trainable" class="md-nav__link">
    <span class="md-ellipsis">
      Making synaptic parameters trainable
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#running-the-simulation" class="md-nav__link">
    <span class="md-ellipsis">
      Running the simulation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stimulating-the-network" class="md-nav__link">
    <span class="md-ellipsis">
      Stimulating the network
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#defining-a-loss-function" class="md-nav__link">
    <span class="md-ellipsis">
      Defining a loss function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#defining-parameter-transformations" class="md-nav__link">
    <span class="md-ellipsis">
      Defining parameter transformations
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#using-checkpointing" class="md-nav__link">
    <span class="md-ellipsis">
      Using checkpointing
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training" class="md-nav__link">
    <span class="md-ellipsis">
      Training
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#writing-a-dataloader" class="md-nav__link">
    <span class="md-ellipsis">
      Writing a dataloader
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-loop" class="md-nav__link">
    <span class="md-ellipsis">
      Training loop
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="training-biophysical-models">Training biophysical models<a class="headerlink" href="#training-biophysical-models" title="Permanent link">&para;</a></h1>
<p>In this tutorial, you will learn how to train biophysical models in <code>Jaxley</code>. This includes the following:</p>
<ul>
<li>compute the gradient with respect to parameters  </li>
<li>use parameter transformations  </li>
<li>use multi-level checkpointing  </li>
<li>define optimizers  </li>
<li>write dataloaders and parallelize across data  </li>
</ul>
<p>Here is a code snippet which you will learn to understand in this tutorial:
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">jax</span><span class="w"> </span><span class="kn">import</span> <span class="n">jit</span><span class="p">,</span> <span class="n">vmap</span><span class="p">,</span> <span class="n">value_and_grad</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jaxley</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jx</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jaxley.optimize.transforms</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jt</span>

<span class="n">net</span> <span class="o">=</span> <span class="o">...</span>  <span class="c1"># See tutorial on the basics of `Jaxley`.</span>

<span class="c1"># Define which parameters to train.</span>
<span class="n">net</span><span class="o">.</span><span class="n">cell</span><span class="p">(</span><span class="s2">&quot;all&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">make_trainable</span><span class="p">(</span><span class="s2">&quot;HH_gNa&quot;</span><span class="p">)</span>
<span class="n">net</span><span class="o">.</span><span class="n">IonotropicSynapse</span><span class="o">.</span><span class="n">make_trainable</span><span class="p">(</span><span class="s2">&quot;IonotropicSynapse_gS&quot;</span><span class="p">)</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span>

<span class="c1"># Define parameter transform and apply it to the parameters.</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">jx</span><span class="o">.</span><span class="n">ParamTransform</span><span class="p">([</span>
    <span class="p">{</span><span class="s2">&quot;IonotropicSynapse_gS&quot;</span><span class="p">:</span> <span class="n">jt</span><span class="o">.</span><span class="n">SigmoidTransform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)},</span>
    <span class="p">{</span><span class="s2">&quot;HH_gNa&quot;</span><span class="p">:</span><span class="n">jt</span><span class="o">.</span><span class="n">SigmoidTransform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)}</span>
<span class="p">])</span>

<span class="n">opt_params</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>

<span class="c1"># Define simulation and batch it across stimuli.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">simulate</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">datapoint</span><span class="p">):</span>
    <span class="n">current</span> <span class="o">=</span> <span class="n">jx</span><span class="o">.</span><span class="n">datapoint_to_step_currents</span><span class="p">(</span><span class="n">i_delay</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">i_dur</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">i_amps</span><span class="o">=</span><span class="n">datapoint</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="mf">0.025</span><span class="p">,</span> <span class="n">t_max</span><span class="o">=</span><span class="mf">5.0</span><span class="p">)</span>
    <span class="n">data_stimuli</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">cell</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">branch</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">comp</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">data_stimulate</span><span class="p">(</span><span class="n">current</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">jx</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">data_stimuli</span><span class="o">=</span><span class="n">data_stimuli</span><span class="p">,</span> <span class="n">checkpoint_inds</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span> <span class="n">delta_t</span><span class="o">=</span><span class="mf">0.025</span><span class="p">)</span>

<span class="n">batch_simulate</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">simulate</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>

<span class="c1"># Define loss function and its gradient.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">loss_fn</span><span class="p">(</span><span class="n">opt_params</span><span class="p">,</span> <span class="n">datapoints</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">opt_params</span><span class="p">)</span>
    <span class="n">voltages</span> <span class="o">=</span> <span class="n">batch_simulate</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">datapoints</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">voltages</span><span class="p">)</span> <span class="o">-</span> <span class="n">label</span><span class="p">)</span>

<span class="n">grad_fn</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">value_and_grad</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

<span class="c1"># Define data and dataloader.</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">dataloader</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">dataloader</span><span class="o">.</span><span class="n">cardinality</span><span class="p">())</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

<span class="c1"># Define the optimizer.</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">opt_state</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">opt_params</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
        <span class="n">stimuli</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">gradient</span> <span class="o">=</span> <span class="n">grad_fn</span><span class="p">(</span><span class="n">opt_params</span><span class="p">,</span> <span class="n">stimuli</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="c1"># Optimizer step.</span>
        <span class="n">updates</span><span class="p">,</span> <span class="n">opt_state</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">)</span>
        <span class="n">opt_params</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">apply_updates</span><span class="p">(</span><span class="n">opt_params</span><span class="p">,</span> <span class="n">updates</span><span class="p">)</span>
</code></pre></div></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">jax</span><span class="w"> </span><span class="kn">import</span> <span class="n">config</span>
<span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="s2">&quot;jax_enable_x64&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="s2">&quot;jax_platform_name&quot;</span><span class="p">,</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax.numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jnp</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">jax</span><span class="w"> </span><span class="kn">import</span> <span class="n">jit</span><span class="p">,</span> <span class="n">vmap</span><span class="p">,</span> <span class="n">value_and_grad</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">jaxley</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jx</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">jaxley.channels</span><span class="w"> </span><span class="kn">import</span> <span class="n">Leak</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">jaxley.synapses</span><span class="w"> </span><span class="kn">import</span> <span class="n">TanhRateSynapse</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">jaxley.connect</span><span class="w"> </span><span class="kn">import</span> <span class="n">fully_connect</span>
</code></pre></div>
<p>First, we define a network as you saw in the <a href="https://jaxley.readthedocs.io/en/latest/tutorials/01_morph_neurons.html">previous tutorial</a>:</p>
<div class="highlight"><pre><span></span><code><span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># For synaptic locations.</span>

<span class="n">comp</span> <span class="o">=</span> <span class="n">jx</span><span class="o">.</span><span class="n">Compartment</span><span class="p">()</span>
<span class="n">branch</span> <span class="o">=</span> <span class="n">jx</span><span class="o">.</span><span class="n">Branch</span><span class="p">(</span><span class="n">comp</span><span class="p">,</span> <span class="n">ncomp</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">cell</span> <span class="o">=</span> <span class="n">jx</span><span class="o">.</span><span class="n">Cell</span><span class="p">(</span><span class="n">branch</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">jx</span><span class="o">.</span><span class="n">Network</span><span class="p">([</span><span class="n">cell</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)])</span>

<span class="n">pre</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">cell</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">post</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">cell</span><span class="p">([</span><span class="mi">2</span><span class="p">])</span>
<span class="n">fully_connect</span><span class="p">(</span><span class="n">pre</span><span class="p">,</span> <span class="n">post</span><span class="p">,</span> <span class="n">TanhRateSynapse</span><span class="p">())</span>

<span class="c1"># Change some default values of the tanh synapse.</span>
<span class="n">net</span><span class="o">.</span><span class="n">TanhRateSynapse</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;TanhRateSynapse_x_offset&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mf">60.0</span><span class="p">)</span>
<span class="n">net</span><span class="o">.</span><span class="n">TanhRateSynapse</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;TanhRateSynapse_gS&quot;</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">)</span>
<span class="n">net</span><span class="o">.</span><span class="n">TanhRateSynapse</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;TanhRateSynapse_slope&quot;</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

<span class="n">net</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">Leak</span><span class="p">())</span>
</code></pre></div>
<p>This network consists of three neurons arranged in two layers:</p>
<div class="highlight"><pre><span></span><code><span class="n">net</span><span class="o">.</span><span class="n">compute_xyz</span><span class="p">()</span>
<span class="n">net</span><span class="o">.</span><span class="n">rotate</span><span class="p">(</span><span class="mi">180</span><span class="p">)</span>
<span class="n">net</span><span class="o">.</span><span class="n">arrange_in_layers</span><span class="p">(</span><span class="n">layers</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">within_layer_offset</span><span class="o">=</span><span class="mf">100.0</span><span class="p">,</span> <span class="n">between_layer_offset</span><span class="o">=</span><span class="mf">100.0</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">vis</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">detail</span><span class="o">=</span><span class="s2">&quot;full&quot;</span><span class="p">)</span>
</code></pre></div>
<p><img alt="png" src="../07_gradient_descent_files/07_gradient_descent_5_0.png" /></p>
<p>We consider the last neuron as the output neuron and record the voltage from there:</p>
<div class="highlight"><pre><span></span><code><span class="n">net</span><span class="o">.</span><span class="n">delete_recordings</span><span class="p">()</span>
<span class="n">net</span><span class="o">.</span><span class="n">cell</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">branch</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">loc</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span><span class="o">.</span><span class="n">record</span><span class="p">()</span>
<span class="n">net</span><span class="o">.</span><span class="n">cell</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">branch</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">loc</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span><span class="o">.</span><span class="n">record</span><span class="p">()</span>
<span class="n">net</span><span class="o">.</span><span class="n">cell</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">branch</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">loc</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span><span class="o">.</span><span class="n">record</span><span class="p">()</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>Added 1 recordings. See `.recordings` for details.
Added 1 recordings. See `.recordings` for details.
Added 1 recordings. See `.recordings` for details.
</code></pre></div>

<h3 id="defining-a-dataset">Defining a dataset<a class="headerlink" href="#defining-a-dataset" title="Permanent link">&para;</a></h3>
<p>We will train this biophysical network on a classification task. The inputs will be values and the label is binary:</p>
<div class="highlight"><pre><span></span><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">asarray</span><span class="p">((</span><span class="n">inputs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">inputs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mf">1.0</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">labels</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">inputs</span><span class="p">[</span><span class="n">labels</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="o">~</span><span class="n">labels</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">inputs</span><span class="p">[</span><span class="o">~</span><span class="n">labels</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</code></pre></div>
<p><img alt="png" src="../07_gradient_descent_files/07_gradient_descent_11_0.png" /></p>
<div class="highlight"><pre><span></span><code><span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
</code></pre></div>
<h3 id="defining-trainable-parameters">Defining trainable parameters<a class="headerlink" href="#defining-trainable-parameters" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">net</span><span class="o">.</span><span class="n">delete_trainables</span><span class="p">()</span>
</code></pre></div>
<p>This follows the same API as <code>.set()</code> seen in the previous tutorial. If you want to use a single parameter for all <code>radius</code>es in the entire network, do:</p>
<div class="highlight"><pre><span></span><code><span class="n">net</span><span class="o">.</span><span class="n">make_trainable</span><span class="p">(</span><span class="s2">&quot;radius&quot;</span><span class="p">)</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>Number of newly added trainable parameters: 1. Total number of trainable parameters: 1
</code></pre></div>

<p>We can also define parameters for individual compartments. To do this, use the <code>"all"</code> key. The following defines a separate parameter the sodium conductance for every compartment in the entire network:</p>
<div class="highlight"><pre><span></span><code><span class="n">net</span><span class="o">.</span><span class="n">cell</span><span class="p">(</span><span class="s2">&quot;all&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">branch</span><span class="p">(</span><span class="s2">&quot;all&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">loc</span><span class="p">(</span><span class="s2">&quot;all&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">make_trainable</span><span class="p">(</span><span class="s2">&quot;Leak_gLeak&quot;</span><span class="p">)</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>Number of newly added trainable parameters: 18. Total number of trainable parameters: 19
</code></pre></div>

<h3 id="making-synaptic-parameters-trainable">Making synaptic parameters trainable<a class="headerlink" href="#making-synaptic-parameters-trainable" title="Permanent link">&para;</a></h3>
<p>Synaptic parameters can be made trainable in the exact same way. To use a single parameter for all syanptic conductances in the entire network, do
<div class="highlight"><pre><span></span><code><span class="n">net</span><span class="o">.</span><span class="n">TanhRateSynapse</span><span class="o">.</span><span class="n">make_trainable</span><span class="p">(</span><span class="s2">&quot;TanhRateSynapse_gS&quot;</span><span class="p">)</span>
</code></pre></div></p>
<p>Here, we use a different syanptic conductance for all syanpses. This can be done as follows:</p>
<div class="highlight"><pre><span></span><code><span class="n">net</span><span class="o">.</span><span class="n">TanhRateSynapse</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;all&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">make_trainable</span><span class="p">(</span><span class="s2">&quot;TanhRateSynapse_gS&quot;</span><span class="p">)</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>Number of newly added trainable parameters: 2. Total number of trainable parameters: 21
</code></pre></div>

<h3 id="running-the-simulation">Running the simulation<a class="headerlink" href="#running-the-simulation" title="Permanent link">&para;</a></h3>
<p>Once all parameters are defined, you have to use <code>.get_parameters()</code> to obtain all trainable parameters. This is also the time to check how many trainable parameters your network has:</p>
<div class="highlight"><pre><span></span><code><span class="n">params</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span>
</code></pre></div>
<p>You can now run the simulation with the trainable parameters by passing them to the <code>jx.integrate</code> function.</p>
<div class="highlight"><pre><span></span><code><span class="n">s</span> <span class="o">=</span> <span class="n">jx</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">t_max</span><span class="o">=</span><span class="mf">10.0</span><span class="p">)</span>
</code></pre></div>
<h3 id="stimulating-the-network">Stimulating the network<a class="headerlink" href="#stimulating-the-network" title="Permanent link">&para;</a></h3>
<p>The network above does not yet get any stimuli. We will use the 2D inputs from the dataset to stimulate the two input neurons. The amplitude of the step current corresponds to the input value. Below is the simulator that defines this:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">simulate</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">currents</span> <span class="o">=</span> <span class="n">jx</span><span class="o">.</span><span class="n">datapoint_to_step_currents</span><span class="p">(</span><span class="n">i_delay</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">i_dur</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">i_amp</span><span class="o">=</span><span class="n">inputs</span> <span class="o">/</span> <span class="mi">10</span><span class="p">,</span> <span class="n">delta_t</span><span class="o">=</span><span class="mf">0.025</span><span class="p">,</span> <span class="n">t_max</span><span class="o">=</span><span class="mf">10.0</span><span class="p">)</span>

    <span class="n">data_stimuli</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">data_stimuli</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">cell</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">branch</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">loc</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">data_stimulate</span><span class="p">(</span><span class="n">currents</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">data_stimuli</span><span class="o">=</span><span class="n">data_stimuli</span><span class="p">)</span>
    <span class="n">data_stimuli</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">cell</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">branch</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">loc</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">data_stimulate</span><span class="p">(</span><span class="n">currents</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">data_stimuli</span><span class="o">=</span><span class="n">data_stimuli</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">jx</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">data_stimuli</span><span class="o">=</span><span class="n">data_stimuli</span><span class="p">,</span> <span class="n">delta_t</span><span class="o">=</span><span class="mf">0.025</span><span class="p">)</span>

<span class="n">batched_simulate</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">simulate</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
</code></pre></div>
<p>We can also inspect some traces:</p>
<div class="highlight"><pre><span></span><code><span class="n">traces</span> <span class="o">=</span> <span class="n">batched_simulate</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[:</span><span class="mi">4</span><span class="p">])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">traces</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</code></pre></div>
<p><img alt="png" src="../07_gradient_descent_files/07_gradient_descent_32_0.png" /></p>
<h3 id="defining-a-loss-function">Defining a loss function<a class="headerlink" href="#defining-a-loss-function" title="Permanent link">&para;</a></h3>
<p>Let us define a loss function to be optimized:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">loss</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">traces</span> <span class="o">=</span> <span class="n">batched_simulate</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>  <span class="c1"># Shape `(batchsize, num_recordings, timepoints)`.</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">traces</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Use the average over time of the output neuron (2) as prediction.</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="p">(</span><span class="n">prediction</span> <span class="o">+</span> <span class="mf">72.0</span><span class="p">)</span> <span class="o">/</span> <span class="mi">5</span>  <span class="c1"># Such that the prediction is roughly in [0, 1].</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">prediction</span> <span class="o">-</span> <span class="n">labels</span><span class="p">)</span>  <span class="c1"># Mean absolute error loss.</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>  <span class="c1"># Average across the batch.</span>
</code></pre></div>
<p>And we can use <code>JAX</code>&rsquo;s inbuilt functions to take the gradient through the entire ODE:</p>
<div class="highlight"><pre><span></span><code><span class="n">jitted_grad</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">value_and_grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">value</span><span class="p">,</span> <span class="n">gradient</span> <span class="o">=</span> <span class="n">jitted_grad</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[:</span><span class="mi">4</span><span class="p">],</span> <span class="n">labels</span><span class="p">[:</span><span class="mi">4</span><span class="p">])</span>
</code></pre></div>
<h3 id="defining-parameter-transformations">Defining parameter transformations<a class="headerlink" href="#defining-parameter-transformations" title="Permanent link">&para;</a></h3>
<p>Before training, however, we will enforce for all parameters to be within a prespecified range (such that, e.g., conductances can not become negative)</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">jaxley.optimize.transforms</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jt</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># Define a function to create appropriate transforms for each parameter</span>
<span class="k">def</span><span class="w"> </span><span class="nf">create_transform</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;axial_resistivity&quot;</span><span class="p">:</span>
        <span class="c1"># Must be positive; apply Softplus and scale to match initialization</span>
        <span class="k">return</span> <span class="n">jt</span><span class="o">.</span><span class="n">ChainTransform</span><span class="p">([</span><span class="n">jt</span><span class="o">.</span><span class="n">SoftplusTransform</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">jt</span><span class="o">.</span><span class="n">AffineTransform</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">0</span><span class="p">)])</span>
    <span class="k">elif</span> <span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;length&quot;</span><span class="p">:</span>
        <span class="c1"># Apply Softplus and affine transform for the &#39;length&#39; parameter</span>
        <span class="k">return</span> <span class="n">jt</span><span class="o">.</span><span class="n">ChainTransform</span><span class="p">([</span><span class="n">jt</span><span class="o">.</span><span class="n">SoftplusTransform</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">jt</span><span class="o">.</span><span class="n">AffineTransform</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">)])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Default to a Softplus transform for other parameters</span>
        <span class="k">return</span> <span class="n">jt</span><span class="o">.</span><span class="n">SoftplusTransform</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Apply the transforms to the parameters</span>
<span class="n">transforms</span> <span class="o">=</span> <span class="p">[{</span><span class="n">k</span><span class="p">:</span> <span class="n">create_transform</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">param</span><span class="p">}</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">]</span>
<span class="n">tf</span> <span class="o">=</span> <span class="n">jt</span><span class="o">.</span><span class="n">ParamTransform</span><span class="p">(</span><span class="n">transforms</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">transform</span> <span class="o">=</span> <span class="n">jx</span><span class="o">.</span><span class="n">ParamTransform</span><span class="p">([{</span><span class="s2">&quot;radius&quot;</span><span class="p">:</span> <span class="n">jt</span><span class="o">.</span><span class="n">SigmoidTransform</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">)},</span>
                               <span class="p">{</span><span class="s2">&quot;Leak_gLeak&quot;</span><span class="p">:</span><span class="n">jt</span><span class="o">.</span><span class="n">SigmoidTransform</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">)},</span>
                               <span class="p">{</span><span class="s2">&quot;TanhRateSynapse_gS&quot;</span> <span class="p">:</span> <span class="n">jt</span><span class="o">.</span><span class="n">SigmoidTransform</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">)}])</span>
</code></pre></div>
<p>With these  modify the loss function acocrdingly:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">loss</span><span class="p">(</span><span class="n">opt_params</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">transform</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">opt_params</span><span class="p">)</span>

    <span class="n">traces</span> <span class="o">=</span> <span class="n">batched_simulate</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>  <span class="c1"># Shape `(batchsize, num_recordings, timepoints)`.</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">traces</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Use the average over time of the output neuron (2) as prediction.</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="p">(</span><span class="n">prediction</span> <span class="o">+</span> <span class="mf">72.0</span><span class="p">)</span>  <span class="c1"># Such that the prediction is around 0.</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">prediction</span> <span class="o">-</span> <span class="n">labels</span><span class="p">)</span>  <span class="c1"># Mean absolute error loss.</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>  <span class="c1"># Average across the batch.</span>
</code></pre></div>
<h3 id="using-checkpointing">Using checkpointing<a class="headerlink" href="#using-checkpointing" title="Permanent link">&para;</a></h3>
<p>Checkpointing allows to vastly reduce the memory requirements of training biophysical models (see also <a href="https://jax.readthedocs.io/en/latest/gradient-checkpointing.html">JAX&rsquo;s full tutorial on checkpointing</a>).</p>
<div class="highlight"><pre><span></span><code><span class="n">t_max</span> <span class="o">=</span> <span class="mf">5.0</span>
<span class="n">dt</span> <span class="o">=</span> <span class="mf">0.025</span>

<span class="n">levels</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">time_points</span> <span class="o">=</span> <span class="n">t_max</span> <span class="o">//</span> <span class="n">dt</span> <span class="o">+</span> <span class="mi">2</span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">time_points</span><span class="o">**</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">levels</span><span class="p">)))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">levels</span><span class="p">)]</span>
</code></pre></div>
<p>To enable checkpointing, we have to modify the <code>simulate</code> function appropriately and use
<div class="highlight"><pre><span></span><code><span class="n">jx</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">checkpoint_inds</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">)</span>
</code></pre></div>
as done below:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">simulate</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">currents</span> <span class="o">=</span> <span class="n">jx</span><span class="o">.</span><span class="n">datapoint_to_step_currents</span><span class="p">(</span><span class="n">i_delay</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">i_dur</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">i_amp</span><span class="o">=</span><span class="n">inputs</span> <span class="o">/</span> <span class="mf">10.0</span><span class="p">,</span> <span class="n">delta_t</span><span class="o">=</span><span class="n">dt</span><span class="p">,</span> <span class="n">t_max</span><span class="o">=</span><span class="n">t_max</span><span class="p">)</span>

    <span class="n">data_stimuli</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">data_stimuli</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">cell</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">branch</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">loc</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">data_stimulate</span><span class="p">(</span><span class="n">currents</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">data_stimuli</span><span class="o">=</span><span class="n">data_stimuli</span><span class="p">)</span>
    <span class="n">data_stimuli</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">cell</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">branch</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">loc</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">data_stimulate</span><span class="p">(</span><span class="n">currents</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">data_stimuli</span><span class="o">=</span><span class="n">data_stimuli</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">jx</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">data_stimuli</span><span class="o">=</span><span class="n">data_stimuli</span><span class="p">,</span> <span class="n">checkpoint_lengths</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">)</span>

<span class="n">batched_simulate</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">simulate</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">traces</span> <span class="o">=</span> <span class="n">simulate</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>  <span class="c1"># Shape `(batchsize, num_recordings, timepoints)`.</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">traces</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>  <span class="c1"># Use the average over time of the output neuron (2) as prediction.</span>
    <span class="k">return</span> <span class="n">prediction</span> <span class="o">+</span> <span class="mf">72.0</span>  <span class="c1"># Such that the prediction is around 0.</span>

<span class="n">batched_predict</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">loss</span><span class="p">(</span><span class="n">opt_params</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">opt_params</span><span class="p">)</span>

    <span class="n">predictions</span> <span class="o">=</span> <span class="n">batched_predict</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">predictions</span> <span class="o">-</span> <span class="n">labels</span><span class="p">)</span>  <span class="c1"># Mean absolute error loss.</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>  <span class="c1"># Average across the batch.</span>

<span class="n">jitted_grad</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">value_and_grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</code></pre></div>
<h3 id="training">Training<a class="headerlink" href="#training" title="Permanent link">&para;</a></h3>
<p>We will use the ADAM optimizer from the <a href="https://optax.readthedocs.io/en/latest/">optax library</a> to optimize the free parameters (you have to install the package with <code>pip install optax</code> first):</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">optax</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">opt_params</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">opt_state</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">opt_params</span><span class="p">)</span>
</code></pre></div>
<h3 id="writing-a-dataloader">Writing a dataloader<a class="headerlink" href="#writing-a-dataloader" title="Permanent link">&para;</a></h3>
<p>Below, we just write our own (very simple) dataloader. Alternatively, you could use the dataloader from any deep learning library such as pytorch or tensorflow:</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">Dataset</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">labels</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Simple Dataloader.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs: Array of shape (num_samples, num_dim)</span>
<span class="sd">            labels: Array of shape (num_samples,)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span> <span class="s2">&quot;Inputs and labels must have same length&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_rng_state</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">shuffle</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Shuffle the dataset in-place&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_rng_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">get_state</span><span class="p">()[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">seed</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_rng_state</span><span class="p">)</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create batches of the data&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_rng_state</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">start</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">start</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">)</span>
            <span class="k">yield</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_rng_state</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div>
<h3 id="training-loop">Training loop<a class="headerlink" href="#training-loop" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">dataloader</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">for</span> <span class="n">batch_ind</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="n">current_batch</span><span class="p">,</span> <span class="n">label_batch</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">loss_val</span><span class="p">,</span> <span class="n">gradient</span> <span class="o">=</span> <span class="n">jitted_grad</span><span class="p">(</span><span class="n">opt_params</span><span class="p">,</span> <span class="n">current_batch</span><span class="p">,</span> <span class="n">label_batch</span><span class="p">)</span>
        <span class="n">updates</span><span class="p">,</span> <span class="n">opt_state</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">)</span>
        <span class="n">opt_params</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">apply_updates</span><span class="p">(</span><span class="n">opt_params</span><span class="p">,</span> <span class="n">updates</span><span class="p">)</span>
        <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss_val</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">, loss </span><span class="si">{</span><span class="n">epoch_loss</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">final_params</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">opt_params</span><span class="p">)</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>epoch 0, loss 25.033223182772293
epoch 1, loss 21.00894915349165
epoch 2, loss 15.092242959956026
epoch 3, loss 9.061544660383163
epoch 4, loss 6.925509860325612
epoch 5, loss 6.273630037897756
epoch 6, loss 6.1757316054693145
epoch 7, loss 6.135132525725265
epoch 8, loss 6.145608619185389
epoch 9, loss 6.135660902068834
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">ntest</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">batched_predict</span><span class="p">(</span><span class="n">final_params</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[:</span><span class="n">ntest</span><span class="p">])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">labels</span><span class="p">[:</span><span class="n">ntest</span><span class="p">],</span> <span class="n">predictions</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Label&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Prediction&quot;</span><span class="p">)</span>
</code></pre></div>
<p><img alt="png" src="../07_gradient_descent_files/07_gradient_descent_60_0.png" /></p>
<p>Indeed, the loss goes down and the network successfully classifies the patterns.</p>
<h3 id="summary">Summary<a class="headerlink" href="#summary" title="Permanent link">&para;</a></h3>
<p>Puh, this was a pretty dense tutorial with a lot of material. You should have learned how to:</p>
<ul>
<li>compute the gradient with respect to parameters  </li>
<li>use parameter transformations  </li>
<li>use multi-level checkpointing  </li>
<li>define optimizers  </li>
<li>write dataloaders and parallelize across data  </li>
</ul>
<p>This was the last &ldquo;basic&rdquo; tutorial of the <code>Jaxley</code> toolbox. If you want to learn more, check out our <a href="https://jaxley.readthedocs.io/en/latest/advanced_tutorials.html">Advanced Tutorials</a>. If anything is still unclear please create a <a href="https://github.com/jaxleyverse/jaxley/discussions">discussion</a>. If you find any bugs, please open an <a href="https://github.com/jaxleyverse/jaxley/issues">issue</a>. Happy coding!</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["content.code.copy"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
    
  </body>
</html>