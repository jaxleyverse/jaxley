{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "config.update(\"jax_platform_name\", \"cpu\")\n",
    "\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\".8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from jax import vmap\n",
    "\n",
    "from typing import Optional, List, Dict, Any, Union, Set, Tuple\n",
    "from dataclasses import dataclass, field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swc_to_morph_tree(fname: str, num_lines: Optional[int] = None) -> MorphTree:\n",
    "    i_id_xyzr_p = np.loadtxt(fname)[:num_lines]\n",
    "    \n",
    "    node_attrs, edge_attrs = {}, {}\n",
    "    for i, id, x, y, z, r, p in i_id_xyzr_p.tolist(): # tolist: np.float64 -> float\n",
    "        node_attrs[int(i)] = {\"id\": int(id), \"x\": x, \"y\": y, \"z\": z, \"r\": r}\n",
    "        if p != -1:\n",
    "            edge_attrs[int(p), int(i)] = {}\n",
    "    \n",
    "    return MorphTree(node_attrs, edge_attrs)\n",
    "\n",
    "@jax.tree_util.register_dataclass\n",
    "@dataclass\n",
    "class MorphTree:\n",
    "    node_attrs: Dict[int, Dict[str, Any]]\n",
    "    edge_attrs: Dict[Tuple[int, int], Dict[str, Any]]\n",
    "    global_attrs: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "    @property\n",
    "    def nodes(self) -> jnp.ndarray:\n",
    "        return jnp.array(list(self.node_attrs.keys())).astype(int)\n",
    "\n",
    "    @property\n",
    "    def edges(self) -> jnp.ndarray:\n",
    "        return jnp.array(list(self.edge_attrs.keys())).astype(int)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        n_nodes = len(self.node_attrs)\n",
    "        n_edges = len(self.edge_attrs)\n",
    "\n",
    "        node_keys = list(next(iter(self.node_attrs.values())).keys())\n",
    "        if len(self.edge_attrs) > 0:\n",
    "            edge_keys = list(next(iter(self.edge_attrs.values())).keys())\n",
    "        else:\n",
    "            edge_keys = []\n",
    "\n",
    "        node_attrs = node_keys if len(self.node_attrs) > 0 else []\n",
    "        edge_attrs = edge_keys if len(self.edge_attrs) > 0 else []\n",
    "        return f\"MorphTree(nodes={n_nodes}*{node_attrs}, edges={n_edges}*{edge_attrs}, global={list(self.global_attrs.keys())})\"\n",
    "    \n",
    "    def node(self, i: int) -> Dict[str, Any]:\n",
    "        return self.node_attrs[i]\n",
    "    \n",
    "    def edge(self, i: int, j: int) -> Dict[str, Any]:\n",
    "        return self.edge_attrs[i, j]\n",
    "    \n",
    "    def to_nx(self) -> nx.DiGraph:\n",
    "        G = nx.DiGraph()\n",
    "        G.add_nodes_from(self.node_attrs.items())\n",
    "        G.add_edges_from((i, j, d) for (i, j), d in self.edge_attrs.items())\n",
    "        G.graph.update(self.global_attrs)\n",
    "        return G\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_nx(G: nx.DiGraph) -> MorphTree:\n",
    "        node_attrs = {n: G.nodes[n] for n in G.nodes}\n",
    "        edge_attrs = {(i, j): G.edges[i, j] for i, j in G.edges}\n",
    "        return MorphTree(node_attrs, edge_attrs, G.graph)\n",
    "    \n",
    "    def to_pandas(self, return_global_attrs: bool = True) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        node_df = pd.DataFrame(self.node_attrs.values(), index=self.node_attrs.keys())\n",
    "        edge_df = pd.DataFrame(self.edge_attrs.values(), index=self.edge_attrs.keys())\n",
    "        edge_index = pd.MultiIndex.from_arrays(np.array(self.edges).T)\n",
    "        edge_df = edge_df.set_index(edge_index)\n",
    "\n",
    "        if return_global_attrs:\n",
    "            return node_df, edge_df, pd.Series(self.global_attrs)\n",
    "        return node_df, edge_df\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_pandas(node_df: pd.DataFrame, edge_df: pd.DataFrame, global_attrs: pd.Series = pd.Series()) -> MorphTree:\n",
    "        node_attrs = node_df.to_dict(orient=\"index\")\n",
    "        edge_attrs = edge_df.to_dict(orient=\"index\")\n",
    "        return MorphTree(node_attrs, edge_attrs, global_attrs.to_dict())\n",
    "    \n",
    "    def plot(self, dims=(0,1),**kwargs: Any) -> None:\n",
    "        G = self.to_nx()\n",
    "        pos = {}\n",
    "        dims2axes = {0: \"x\", 1: \"y\", 2: \"z\"}\n",
    "        for n, attr in G.nodes(data=True):\n",
    "            if \"x\" in attr:  # assume y is also present\n",
    "                pos[n] = (attr[dims2axes[dims[0]]], attr[dims2axes[dims[1]]])\n",
    "        nx.draw(G, pos, with_labels=True, **kwargs)\n",
    "        plt.show()\n",
    "\n",
    "    def reindex_nodes(self, mapping: dict) -> MorphTree:\n",
    "        new_node_attrs = {mapping[i]: attrs for i, attrs in self.node_attrs.items()}\n",
    "        \n",
    "        new_edge_attrs = {}\n",
    "        for (i, j), attrs in self.edge_attrs.items():\n",
    "            new_edge_attrs[(mapping[i], mapping[j])] = attrs\n",
    "            \n",
    "        return MorphTree(new_node_attrs, new_edge_attrs, self.global_attrs)\n",
    "    \n",
    "    def reorder_tree(self, new_order: np.ndarray) -> MorphTree:\n",
    "        # TODO: check this does what I think it does, i.e. change the edge orientation\n",
    "        # in order of appearance of the nodes in self.nodes.\n",
    "        edges = np.array(self.edges)\n",
    "        idx_i = np.where(edges[:,0] == new_order[:, None])[0]\n",
    "        idx_j = np.where(edges[:,1] == new_order[:, None])[0]\n",
    "        is_descending = ~(idx_i < idx_j)\n",
    "        for (i,j) in edges[is_descending]:\n",
    "            print(i,j)\n",
    "            self.edge_attrs[j, i] = self.edge_attrs.pop((i, j))\n",
    "        return self\n",
    "    \n",
    "    def subgraph(self, nodes: List[int]) -> MorphTree:\n",
    "        node_attrs_subset = {i: self.node_attrs[i] for i in nodes}\n",
    "        edge_attrs_subset = {(i,j): attrs for (i,j), attrs in self.edge_attrs.items() if i in nodes and j in nodes}\n",
    "        return MorphTree(node_attrs_subset, edge_attrs_subset, self.global_attrs)\n",
    "\n",
    "def list_branches(tree: MorphTree, return_branchpoints: bool = False) -> Union[List[List[int]], Tuple[List[List[int]], Set[int], List[Tuple[int, int]]]]:\n",
    "    G = tree.to_nx().to_undirected()\n",
    "    branches = []\n",
    "    branchpoints = set()\n",
    "    visited = set()\n",
    "\n",
    "    def is_branchpoint_or_tip(n: int) -> bool:\n",
    "        is_leaf = G.degree(n) <= 1\n",
    "        is_branching = G.degree(n) > 2\n",
    "        if G.degree(n) == 2:\n",
    "            i,j = G.neighbors(n)\n",
    "             # trace dir matters here! For segment with node IDs: [1, 1, 2, 2]\n",
    "             # -> [[1,1], [1,2,2]] \n",
    "             # <- [[2,2], [2,1,1]] \n",
    "            return not same_id(n, j)\n",
    "        \n",
    "        return is_leaf or is_branching\n",
    "\n",
    "    def in_visited(n1: int, n2: int) -> bool:\n",
    "        return (n1, n2) in visited or (n2, n1) in visited\n",
    "\n",
    "    def same_id(n1: int, n2: int) -> bool:\n",
    "        return G.nodes[n1][\"id\"] == G.nodes[n2][\"id\"] if \"id\" in G.nodes[n1] else True\n",
    "\n",
    "    def is_soma(n: int) -> bool:\n",
    "        return G.nodes[n][\"id\"] == 1\n",
    "    \n",
    "    def soma_nodes() -> bool:\n",
    "        return [i for i, n in G.nodes.items() if n[\"id\"] == 1]\n",
    "\n",
    "    def walk_path(start: int, succ: int) -> List[int]:\n",
    "        path = [start, succ]\n",
    "        visited.add((start, succ))\n",
    " \n",
    "        while G.degree(succ) == 2:\n",
    "            next_node = next(n for n in G.neighbors(succ) if n != path[-2])\n",
    "\n",
    "            if in_visited(succ, next_node) or is_branchpoint_or_tip(succ):\n",
    "                break\n",
    "            \n",
    "            path.append(next_node)\n",
    "            visited.add((succ, next_node))\n",
    "            succ = next_node\n",
    "\n",
    "        return path\n",
    "\n",
    "    leaf = next(n for n in G.nodes if G.degree(n) == 1)\n",
    "    single_soma = len(soma_nodes()) == 1\n",
    "    for node in nx.dfs_tree(G, leaf):\n",
    "        if single_soma and is_soma(node):\n",
    "            branches.append([node])\n",
    "\n",
    "        elif is_branchpoint_or_tip(node):\n",
    "            branchpoints.add(node)\n",
    "            for succ in G.neighbors(node):\n",
    "                if not in_visited(node, succ):\n",
    "                    branches.append(walk_path(node, succ))\n",
    "    \n",
    "    if return_branchpoints:\n",
    "        branchpoint_edges = sum([list(G.edges(n)) for n in branchpoints], [])\n",
    "        return branches, branchpoints, branchpoint_edges\n",
    "    return branches\n",
    "\n",
    "def _find_swc_tracing_interruptions(tree: MorphTree) -> np.ndarray:\n",
    "    G = tree.to_nx()\n",
    "    degree_is_2 = lambda n: G.out_degree(n) + G.in_degree(n) == 2\n",
    "\n",
    "    interrupt_edges = []\n",
    "    for n in G.nodes:\n",
    "        if len(parents := list(G.predecessors(n))) > 0:\n",
    "            p = parents[0] \n",
    "            if p != n-1 and degree_is_2(n) and degree_is_2(p):\n",
    "                interrupt_edges.append((p,n))\n",
    "    return interrupt_edges\n",
    "\n",
    "def _split_interrupted_branches(branches, split_edges) -> MorphTree:\n",
    "    for (p,n) in split_edges:\n",
    "        for i, branch in enumerate(branches):\n",
    "            if n in branch:\n",
    "                split_idx = branch.index(n)\n",
    "                branches[i:i+1] = [branch[:split_idx], branch[split_idx:]]\n",
    "                break\n",
    "    return branches\n",
    "\n",
    "def compute_xyz(tree: MorphTree,  length=1.0,  spread=np.pi/8, spread_decay=0.9,  twist=0.0, xy_only=True):\n",
    "    # TODO: Replace compute_xyz with this or vice versa, redundant!\n",
    "    G = tree.to_nx()\n",
    "    root = next(n for n, d in G.in_degree() if d == 0)\n",
    "    pos = {root: (0.0, 0.0, 0.0)}\n",
    "\n",
    "    def recurse(node, depth=1, theta=0.0, phi=np.pi/2):\n",
    "        children = [n for n in G.successors(node) if n not in pos]\n",
    "        if not children: return\n",
    "        n = len(children)\n",
    "        curr_spread = spread * (spread_decay ** (depth - 1))\n",
    "        x0, y0, z0 = pos[node]\n",
    "        phi = np.pi/2 if xy_only else phi\n",
    "        base_theta = theta + depth * twist\n",
    "        if n == 1:\n",
    "            thetas, phis = [base_theta], [phi]\n",
    "        else:\n",
    "            if xy_only:\n",
    "                thetas = np.linspace(base_theta - curr_spread/2, base_theta + curr_spread/2, n)\n",
    "                phis = [phi] * n\n",
    "            else:\n",
    "                thetas = np.linspace(base_theta, base_theta + 2 * np.pi, n, endpoint=False)\n",
    "                phis = [phi - curr_spread] * n\n",
    "        for th, ph, child in zip(thetas, phis, children):\n",
    "            x = x0 + length * np.sin(ph) * np.cos(th)\n",
    "            y = y0 + length * np.sin(ph) * np.sin(th)\n",
    "            z = z0 + length * np.cos(ph) * (not xy_only)\n",
    "            pos[child] = (x, y, z)\n",
    "            recurse(child, depth + 1, th, ph)\n",
    "\n",
    "    recurse(root, theta=0.0, phi=np.pi/2)\n",
    "    return pos\n",
    "\n",
    "def _add_missing_attrs(tree: MorphTree) -> MorphTree:\n",
    "    defaults = {\"id\": 0, \"r\": 1}\n",
    "    node_attr_keys = next(iter(tree.node_attrs.values())).keys()\n",
    "    xyz = compute_xyz(tree) if \"x\" not in node_attr_keys else {}\n",
    "    for n, (x, y, z) in xyz.items():\n",
    "        tree.node_attrs[n][\"x\"] = x\n",
    "        tree.node_attrs[n][\"y\"] = y\n",
    "        tree.node_attrs[n][\"z\"] = z\n",
    "\n",
    "    missing_attrs = {k: v for k, v in defaults.items() if k not in node_attr_keys}\n",
    "    for n in tree.node_attrs:\n",
    "        tree.node_attrs[n].update(missing_attrs)\n",
    "    return tree\n",
    "\n",
    "def compartmentalize(tree: MorphTree, num_comps: int = 1) -> MorphTree:\n",
    "    tree = _add_missing_attrs(tree)\n",
    "\n",
    "    branches = list_branches(tree)\n",
    "    nodes_df = tree.to_pandas()[0].astype(float)\n",
    "\n",
    "    # create new set of indices which arent already used as node indices to label comps\n",
    "    existing_inds = set(nodes_df.index)\n",
    "    num_new_inds = len(branches)*num_comps\n",
    "    proposed_inds = set(range(num_new_inds + len(existing_inds)))\n",
    "    proposed_comp_inds = list(proposed_inds - existing_inds) # avoid overlap w. node indices\n",
    "    \n",
    "    v_interp = vmap(jnp.interp, in_axes=(None, None, 1), out_axes=1)\n",
    "    \n",
    "    # identify tip nodes (degree == 1)\n",
    "    nodes_in_edges, node_counts_in_edges = np.unique(tree.edges, return_counts=True)\n",
    "    tip_node_inds = nodes_in_edges[node_counts_in_edges == 1]\n",
    "\n",
    "    # collect comps and comp_edges\n",
    "    branch_nodes, branch_edges = [], []\n",
    "    xyzr = []\n",
    "    for i, branch in enumerate(branches):\n",
    "        node_attrs = nodes_df.loc[branch]\n",
    "        xyzr_i = node_attrs[[\"x\", \"y\", \"z\", \"r\"]]\n",
    "        xyzr.append(xyzr_i.values)\n",
    "\n",
    "        xyz_i = xyzr_i[[\"x\", \"y\", \"z\"]]\n",
    "        edge_lens = ((xyz_i.diff(axis=0).fillna(0)**2).sum(axis=1)**.5)\n",
    "        # TODO: handle nans\n",
    "        node_attrs[\"l\"] = edge_lens.cumsum() # path length\n",
    "        \n",
    "        # For single-point somatata, we set l = 2*r this ensures\n",
    "        # A_cylinder = 2*pi*r*l = 4*pi*r^2 = A_sphere.\n",
    "        if len(branch) == 1:\n",
    "            node_attrs = node_attrs.loc[branch*2] # duplicate soma node\n",
    "            radius = node_attrs[\"r\"].iloc[0]\n",
    "            node_attrs[\"l\"] = np.array([0, 2*radius])\n",
    "\n",
    "        branch_id = node_attrs[\"id\"].iloc[-1] # TODO: handle multi ids within branch!\n",
    "        branch_len = max(node_attrs[\"l\"])\n",
    "        comp_len = branch_len / num_comps\n",
    "        comp_locs = list(np.linspace(comp_len/2, branch_len - comp_len/2, num_comps))\n",
    "        \n",
    "        # Create node indices and attributes\n",
    "        # branch_inds, branchpoint, comp_id, comp_len\n",
    "        branch_tips = branch[0], branch[-1]\n",
    "        branch_tip_attrs = [[i, True, node_attrs[\"id\"].iloc[0], 0],\n",
    "                            [i, True, node_attrs[\"id\"].iloc[-1], 0]]\n",
    "        comp_attrs = [i, False, branch_id, comp_len]*num_comps\n",
    "\n",
    "        comp_inds = proposed_comp_inds[i*num_comps:(i+1)*num_comps]\n",
    "        comp_inds = np.array([branch_tips[0], *comp_inds, branch_tips[1]])\n",
    "        comp_attrs = [branch_tip_attrs[0]] + [comp_attrs] + [branch_tip_attrs[1]]\n",
    "        comp_attrs = np.hstack([comp_inds[:, None], comp_attrs])\n",
    "        \n",
    "        # Interpolate xyzr coordinates and combine with attributes\n",
    "        x = jnp.array([0] + comp_locs + [branch_len]) # 0, branch_len = branchpoints\n",
    "        xp = jnp.array(node_attrs[\"l\"].values)\n",
    "        fp = jnp.array(xyzr_i.values)\n",
    "        #TODO: interpolate r differently!\n",
    "        comp_attrs = np.hstack([comp_attrs, np.array(v_interp(x, xp, fp))])\n",
    "        \n",
    "        # remove tip nodes\n",
    "        comp_attrs = comp_attrs[1:] if branch_tips[0] in tip_node_inds else comp_attrs\n",
    "        comp_attrs = comp_attrs[:-1] if branch_tips[1] in tip_node_inds else comp_attrs\n",
    "\n",
    "        # Store edges and nodes\n",
    "        branch_edges.append(list(zip(comp_attrs[:-1, 0], comp_attrs[1:, 0])))\n",
    "        branch_nodes.append(comp_attrs)\n",
    "\n",
    "    branch_nodes = jnp.concatenate(branch_nodes)\n",
    "    comp_attrs_keys = [\"idx\", \"branch_index\", \"branchpoint\", \"id\", \"l\", \"x\", \"y\", \"z\", \"r\"]\n",
    "    comp_df = pd.DataFrame(branch_nodes, columns=comp_attrs_keys)\n",
    "    int_cols = [\"idx\", \"branch_index\", \"id\"] # TODO: rename to branch!\n",
    "    bool_cols = [\"branchpoint\"]\n",
    "    comp_df[int_cols] = comp_df[int_cols].astype(int)\n",
    "    comp_df[bool_cols] = comp_df[bool_cols].astype(bool)\n",
    "    \n",
    "    # drop duplicated branch nodes\n",
    "    comp_df = comp_df.drop_duplicates(subset=[\"idx\"])\n",
    "    comp_df = comp_df.set_index(\"idx\")\n",
    "\n",
    "    comp_attrs = comp_df.to_dict(orient=\"index\")\n",
    "    comp_edges = sum(branch_edges, [])\n",
    "    comp_edge_attrs = {(i,j): {\"comp_edge\": True, \"synapse\": False} for i,j in comp_edges}\n",
    "\n",
    "    global_attrs = {\"xyzr\": xyzr} # TODO: rm xyzr from Module? only used for plotting\n",
    "    comp_tree = MorphTree(comp_attrs, comp_edge_attrs, global_attrs)\n",
    "    comp_tree = comp_tree.reindex_nodes(dict(zip(comp_df.index, range(len(comp_df)))))\n",
    "    return comp_tree\n",
    "\n",
    "def _add_meta_data(tree: MorphTree) -> MorphTree:\n",
    "    group_ids = {0: \"undefined\", 1: \"soma\", 2: \"axon\", 3: \"basal\", 4: \"apical\"}\n",
    "    fill_w = lambda x: np.full(len(tree.nodes), x)\n",
    "\n",
    "    nodes_df, edge_df, global_attrs = tree.to_pandas()\n",
    "    global_attrs = pd.concat([global_attrs, pd.Series({\"channels\": {}, \"synapses\": {}})])\n",
    "    \n",
    "    nodes_df[\"cell_index\"] = fill_w(0) # rename to cell\n",
    "    nodes_df[\"comp_index\"] = np.arange(len(nodes_df)) # rename to comp\n",
    "    nodes_df[\"id\"] = nodes_df[\"id\"].apply(lambda x: [group_ids[x]])\n",
    "    nodes_df = nodes_df.rename(columns={\"r\": \"radius\", \"l\": \"length\", \"id\": \"groups\"})\n",
    "    nodes_df[\"capacitance\"] = fill_w(1.0)\n",
    "    nodes_df[\"v\"] = fill_w(-70.0)\n",
    "    nodes_df[\"axial_resistivity\"] = fill_w(1000.0)\n",
    "\n",
    "    return MorphTree.from_pandas(nodes_df, edge_df, global_attrs)\n",
    "\n",
    "def _remove_branchpoints(tree: MorphTree) -> MorphTree:\n",
    "    G = tree.to_nx()\n",
    "    branchpoints = [n for n in G.nodes if G.nodes[n][\"branchpoint\"]]\n",
    "    for n in branchpoints:\n",
    "        parent = next(G.predecessors(n))\n",
    "        children = list(G.successors(n))\n",
    "        \n",
    "        # remove branchpoint and connect parent to children\n",
    "        G.remove_node(n)\n",
    "        G.add_edges_from([(parent, c) for c in children], comp_edge=True, synapse=False)\n",
    "    \n",
    "    tree = MorphTree.from_nx(G)\n",
    "    for n in tree.node_attrs:\n",
    "        tree.node_attrs[n].pop(\"branchpoint\")\n",
    "    # TODO: relabel comps?\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxley.io.graph import _build_module_scaffold\n",
    "\n",
    "def _build_module(\n",
    "    solve_graph: nx.DiGraph,\n",
    "    assign_groups: bool = True,\n",
    "):\n",
    "    # nodes and edges\n",
    "    node_df = pd.DataFrame(\n",
    "        [d for i, d in solve_graph.nodes(data=True)], index=solve_graph.nodes\n",
    "    ).sort_index()\n",
    "\n",
    "    edge_type = nx.get_edge_attributes(solve_graph, \"type\")\n",
    "    synapse_edges = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"pre_index\": i,\n",
    "                \"post_index\": j,\n",
    "                **solve_graph.edges[i, j],\n",
    "            }\n",
    "            for (i, j), t in edge_type.items()\n",
    "            if t == \"synapse\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # branches\n",
    "    branch_of_node = lambda i: solve_graph.nodes[i][\"branch_index\"]\n",
    "    branch_edges_df = pd.DataFrame(\n",
    "        [\n",
    "            (branch_of_node(i), branch_of_node(j))\n",
    "            for (i, j), t in edge_type.items()\n",
    "            if t == \"inter_branch\"\n",
    "        ],\n",
    "        columns=[\"parent_branch_index\", \"child_branch_index\"],\n",
    "    )\n",
    "\n",
    "    # drop special attrs from nodes and ignore error if col does not exist\n",
    "    # x,y,z can be re-computed from xyzr if needed\n",
    "    optional_attrs = [\n",
    "        \"recordings\",\n",
    "        \"externals\",\n",
    "        \"external_inds\",\n",
    "        \"trainable\",\n",
    "    ]\n",
    "    node_df = node_df.drop(columns=optional_attrs, errors=\"ignore\")\n",
    "\n",
    "    # synapses\n",
    "    synapse_edges = synapse_edges.drop([\"l\", \"type\"], axis=1, errors=\"ignore\")\n",
    "    synapse_edges = synapse_edges.rename({\"syn_type\": \"type\"}, axis=1)\n",
    "    synapse_edges.rename({\"edge_index\": \"global_edge_index\"}, axis=1, inplace=True)\n",
    "\n",
    "    # build module\n",
    "    acc_parents = []\n",
    "    parent_branch_inds = branch_edges_df.set_index(\"child_branch_index\").sort_index()[\n",
    "        \"parent_branch_index\"\n",
    "    ]\n",
    "    assert np.std(node_df.groupby(\"branch_index\").size().to_numpy()) < 1e-8, (\n",
    "        \"`from_graph()` does not support a varying number of compartments in each \"\n",
    "        \"branch.\"\n",
    "    )\n",
    "    for branch_inds in node_df.groupby(\"cell_index\")[\"branch_index\"].unique():\n",
    "        root_branch_idx = branch_inds[0]\n",
    "        parents = parent_branch_inds.loc[branch_inds[1:]] - root_branch_idx\n",
    "        acc_parents.append([-1] + parents.tolist())\n",
    "\n",
    "    # TODO: support inhom ncomps\n",
    "    module = _build_module_scaffold(\n",
    "        node_df, solve_graph.graph[\"type\"], acc_parents, solve_graph.graph[\"xyzr\"]\n",
    "    )\n",
    "\n",
    "    # set global attributes of module. `xyzr` is passed here again, although it has\n",
    "    # already been passed to `_build_module_scaffold`. `jx.Cell` requires xyzr at\n",
    "    # __init__()`, all other modules do not.\n",
    "    for k, v in solve_graph.graph.items():\n",
    "        if k not in [\"type\"]:\n",
    "            setattr(module, k, v)\n",
    "\n",
    "    if assign_groups and \"groups\" in node_df.columns:\n",
    "        groups = node_df.pop(\"groups\").explode()\n",
    "        groups = (\n",
    "            pd.DataFrame(groups)\n",
    "            .groupby(\"groups\")\n",
    "            .apply(lambda x: x.index.values, include_groups=False)\n",
    "            .to_dict()\n",
    "        )\n",
    "        for group_name, group_inds in groups.items():\n",
    "            module.select(nodes=group_inds).add_to_group(group_name)\n",
    "\n",
    "    node_df.columns = [\n",
    "        \"global_\" + col if \"local\" not in col and \"index\" in col else col\n",
    "        for col in node_df.columns\n",
    "    ]\n",
    "    # set column-wise. preserves cols not in df.\n",
    "    module.nodes[node_df.columns] = node_df\n",
    "    module.edges = synapse_edges if not synapse_edges.empty else module.edges\n",
    "\n",
    "    # add all the extra attrs\n",
    "    module.membrane_current_names = [c.current_name for c in module.channels]\n",
    "    module.synapse_names = [s._name for s in module.synapses]\n",
    "\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_tree = swc_to_morph_tree(\"../jaxley/tests/swc_files/morph_ca1_n120.swc\")\n",
    "morph_comps = compartmentalize(morph_tree, num_comps=1)\n",
    "morph_comps = _add_meta_data(morph_comps)\n",
    "morph_comps = _remove_branchpoints(morph_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\\n       ...\\n       145, 146, 147, 148, 149, 150, 151, 152, 153, 154],\\n      dtype='int64', name='child_branch_index', length=154)] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[144], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m_build_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmorph_comps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_nx\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[142], line 62\u001b[0m, in \u001b[0;36m_build_module\u001b[0;34m(solve_graph, assign_groups)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m branch_inds \u001b[38;5;129;01min\u001b[39;00m node_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbranch_index\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n\u001b[1;32m     61\u001b[0m     root_branch_idx \u001b[38;5;241m=\u001b[39m branch_inds[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 62\u001b[0m     parents \u001b[38;5;241m=\u001b[39m \u001b[43mparent_branch_inds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbranch_inds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m root_branch_idx\n\u001b[1;32m     63\u001b[0m     acc_parents\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m parents\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# TODO: support inhom ncomps\u001b[39;00m\n",
      "File \u001b[0;32m~/Uni/PhD/projects/jaxleyverse/jaxley/.venv/lib/python3.12/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Uni/PhD/projects/jaxleyverse/jaxley/.venv/lib/python3.12/site-packages/pandas/core/indexing.py:1420\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1418\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/Uni/PhD/projects/jaxleyverse/jaxley/.venv/lib/python3.12/site-packages/pandas/core/indexing.py:1360\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1360\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1362\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1363\u001b[0m )\n",
      "File \u001b[0;32m~/Uni/PhD/projects/jaxleyverse/jaxley/.venv/lib/python3.12/site-packages/pandas/core/indexing.py:1558\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1555\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1556\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1558\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/Uni/PhD/projects/jaxleyverse/jaxley/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Uni/PhD/projects/jaxleyverse/jaxley/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\\n       ...\\n       145, 146, 147, 148, 149, 150, 151, 152, 153, 154],\\n      dtype='int64', name='child_branch_index', length=154)] are in the [index]\""
     ]
    }
   ],
   "source": [
    "_build_module(morph_comps.to_nx())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[390], line 14\u001b[0m\n\u001b[1;32m      3\u001b[0m edges \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m     (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m),        \u001b[38;5;66;03m# root 0 branches to 1, 2, 3\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m), (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m),                \u001b[38;5;66;03m# node 1 branches to 4, 5\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     (\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m14\u001b[39m), (\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m15\u001b[39m), (\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m16\u001b[39m)      \u001b[38;5;66;03m# node 9 branches to 14, 15, 16\u001b[39;00m\n\u001b[1;32m     11\u001b[0m ]\n\u001b[1;32m     12\u001b[0m G\u001b[38;5;241m.\u001b[39madd_edges_from(edges)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mcompartmentalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMorphTree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_nx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_comps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mplot()\n",
      "Cell \u001b[0;32mIn[388], line 289\u001b[0m, in \u001b[0;36mcompartmentalize\u001b[0;34m(tree, num_comps)\u001b[0m\n\u001b[1;32m    287\u001b[0m comp_inds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([branch_tips[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39mcomp_inds, branch_tips[\u001b[38;5;241m1\u001b[39m]])\n\u001b[1;32m    288\u001b[0m comp_attrs \u001b[38;5;241m=\u001b[39m [branch_tip_attrs[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m+\u001b[39m [comp_attrs] \u001b[38;5;241m+\u001b[39m [branch_tip_attrs[\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m--> 289\u001b[0m comp_attrs \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcomp_inds\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomp_attrs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;66;03m# Interpolate xyzr coordinates and combine with attributes\u001b[39;00m\n\u001b[1;32m    292\u001b[0m x \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m comp_locs \u001b[38;5;241m+\u001b[39m [branch_len]) \u001b[38;5;66;03m# 0, branch_len = branchpoints\u001b[39;00m\n",
      "File \u001b[0;32m~/Uni/PhD/projects/jaxleyverse/jaxley/.venv/lib/python3.12/site-packages/numpy/_core/shape_base.py:360\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_vhstack_dispatcher)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhstack\u001b[39m(tup, \u001b[38;5;241m*\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    297\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;124;03m    Stack arrays in sequence horizontally (column wise).\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    358\u001b[0m \n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m \u001b[43matleast_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    362\u001b[0m         arrs \u001b[38;5;241m=\u001b[39m (arrs,)\n",
      "File \u001b[0;32m~/Uni/PhD/projects/jaxleyverse/jaxley/.venv/lib/python3.12/site-packages/numpy/_core/shape_base.py:69\u001b[0m, in \u001b[0;36matleast_1d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m     67\u001b[0m res \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ary \u001b[38;5;129;01min\u001b[39;00m arys:\n\u001b[0;32m---> 69\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     71\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# TODO: FIX THIS\n",
    "G = nx.DiGraph()\n",
    "edges = [\n",
    "    (0, 1), (0, 2), (0, 3),\n",
    "    (1, 4), (1, 5),\n",
    "    (2, 6), (2, 7), (2, 8),\n",
    "    (3, 9),\n",
    "    (4, 10), (4, 11),\n",
    "    (7, 12), (7, 13),\n",
    "    (9, 14), (9, 15), (9, 16)\n",
    "]\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "compartmentalize(MorphTree.from_nx(G), num_comps=2).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyChannel:\n",
    "    def __init__(self, name = None):\n",
    "        self.name = self.__class__.__name__ if name is None else name\n",
    "        self.params = {f\"gbar_{self.name}\": 1.0, f\"e_{self.name}\": 0.0, f\"nn_weights_{self.name}\": jnp.ones((10, 10))}\n",
    "        self.states = {f\"m_{self.name}\": 0.5, f\"h_{self.name}\": 0.5}\n",
    "\n",
    "def tree_insert(tree, inds, channel):\n",
    "    # TODO: Should Module and MorphTree be separate or the same thing?\n",
    "    tree.global_attrs[\"channels\"][channel.name] = channel\n",
    "    for i in inds:\n",
    "        tree.node_attrs[i].update(channel.params)\n",
    "        tree.node_attrs[i].update(channel.states)\n",
    "\n",
    "def tree_set(tree, key, value):\n",
    "    nodes_df, edge_df = tree.to_pandas()\n",
    "    # if ... if, since param could be in both nodes and edges\n",
    "    if key in nodes_df.columns:\n",
    "        valid = ~nodes_df[key].isna() & ~nodes_df.branchpoint\n",
    "        nodes_df.loc[valid, key] = value\n",
    "    if key in edge_df.columns:\n",
    "        valid = ~edge_df[key].isna() & edge_df.synapse\n",
    "        edge_df.loc[valid, key] = value\n",
    "    return MorphTree.from_pandas(nodes_df, edge_df, pd.Series(tree.global_attrs))\n",
    "\n",
    "    # # not vectorized, but allows to modify in place\n",
    "    # nodes_df, edge_df = tree.to_pandas()\n",
    "    # if key in nodes_df.columns:\n",
    "    #     for i in tree.node_attrs:\n",
    "    #         if key in tree.node_attrs[i]:\n",
    "    #             tree.node_attrs[i][key] = value\n",
    "    # if key in edge_df.columns:\n",
    "    #     for i, j in tree.edge_attrs:\n",
    "    #         if key in tree.edge_attrs[(i,j)]:\n",
    "    #             tree.edge_attrs[(i,j)][key] = value\n",
    "\n",
    "\n",
    "#TODO: split/merge similar to equinox\n",
    "def merge_trees(trees: List[MorphTree]) -> MorphTree:\n",
    "    tree = trees[0]\n",
    "    for t in trees[1:]:\n",
    "        tree.node_attrs.update(t.node_attrs)\n",
    "        tree.edge_attrs.update(t.edge_attrs)\n",
    "    return tree\n",
    "\n",
    "# def split_tree(tree: MorphTree, nodes: List[int]) -> List[MorphTree]:\n",
    "#     pass\n",
    "\n",
    "def tree_to_pytree(tree):\n",
    "    nodes_df, edge_df = tree.to_pandas()\n",
    "    jax_nodes, jax_edges = {}, {}\n",
    "    \n",
    "    node_data = nodes_df.loc[~nodes_df.branchpoint]\n",
    "    node_data = node_data.drop(columns=[\"branch\", \"branchpoint\", \"groups\"])\n",
    "    for key in node_data.columns:\n",
    "        values = jnp.array(node_data.loc[~node_data[key].isna(), key].to_list())\n",
    "        jax_nodes[key] = values\n",
    "\n",
    "    edge_data = edge_df.loc[edge_df.synapse]\n",
    "    edge_data = edge_data.drop(columns=[\"comp_edge\", \"synapse\"])\n",
    "    for key in edge_data.columns:\n",
    "        values = jnp.array(edge_data.loc[~edge_data[key].isna(), key].to_list())\n",
    "        jax_edges[key] = values\n",
    "    return jax_nodes, jax_edges\n",
    "\n",
    "def tree_view(tree: MorphTree, nodes: List[int]) -> MorphTree:\n",
    "    return tree.subgraph(nodes)\n",
    "\n",
    "class DummySynapse:\n",
    "    def __init__(self, name = None):\n",
    "        self.name = self.__class__.__name__ if name is None else name\n",
    "        self.params = {f\"gbar_{self.name}\": 1.0, f\"e_{self.name}\": 0.0, f\"nn_weights_{self.name}\": jnp.ones((10, 10))}\n",
    "        self.states = {f\"m_{self.name}\": 0.5, f\"h_{self.name}\": 0.5}\n",
    "\n",
    "def tree_connect(tree, pre, post, synapse):\n",
    "    # TODO: map / vectorize this\n",
    "    tree.global_attrs[\"synapses\"][synapse.name] = synapse\n",
    "    for i, j in zip(pre, post):\n",
    "        if (i,j) not in tree.edge_attrs:\n",
    "            tree.edge_attrs[(i,j)] = {\"comp_edge\": False}\n",
    "        tree.edge_attrs[i, j][\"synapse\"] = True\n",
    "        tree.edge_attrs[i, j].update(synapse.params)\n",
    "        tree.edge_attrs[i, j].update(synapse.states)\n",
    "\n",
    "\n",
    "# There can only be one edge per pair of nodes. (or use MultiDiGraph).\n",
    "# This means all synapses need to live in the same edge (i,j)\n",
    "# -> treat synapses more like channels, i.e. multiple channels per row in nodes -> multiple synapses per edge.\n",
    "# downside cannot connect i and j with the same synapse twice, but can do if one synapse is named differently.\n",
    "# think about how to handle if i,j is a comp_edge and also connects via synapses\n",
    "\n",
    "# TODO: node and edge attrs as list or dict?\n",
    "# - pro: one can change node / edge idx without changing touching attrs, since pos of node_idx -> pos node_attr\n",
    "# - con: hard to index into node / edge attrs\n",
    "\n",
    "# TODO: get rid of xyzr in most usecases and use the comp / node xyzrs!? -> simplifies all plotting to networkx!\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxley.io.graph import build_compartment_graph, to_swc_graph, _trace_branches, _remove_branch_points\n",
    "\n",
    "testcases = [ \n",
    "\"morph_3_types_single_point_soma.swc\",\n",
    "\"morph_3_types.swc\",\n",
    "\"morph_interrupted_soma.swc\",\n",
    "\"morph_soma_both_ends.swc\",\n",
    "\"morph_somatic_branchpoint.swc\",\n",
    "\"morph_non_somatic_branchpoint.swc\", # no soma!\n",
    "\"morph_ca1_n120_single_point_soma.swc\",\n",
    "\"morph_ca1_n120.swc\",\n",
    "\"morph_l5pc_with_axon.swc\",\n",
    "\"morph_allen_485574832.swc\",\n",
    "]\n",
    "\n",
    "jx_graph = to_swc_graph(\"../jaxley/tests/swc_files/\"+testcases[-3])\n",
    "# jx_comps = build_compartment_graph(jx_graph.copy(), ncomp=1)\n",
    "\n",
    "morph_tree = swc_to_morph_tree(\"../jaxley/tests/swc_files/\"+testcases[-3])\n",
    "morph_comps = compartmentalize(morph_tree, num_comps=1)\n",
    "morph_comps = _add_meta_data(morph_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_insert(morph_comps, [0, 2], DummyChannel(\"test1\"))\n",
    "tree_insert(morph_comps, [0, 2], DummyChannel(\"test2\"))\n",
    "\n",
    "tree_connect(morph_comps, [0, 1], [3, 2], DummySynapse(\"test1\"))\n",
    "tree_connect(morph_comps, [0, 1], [1, 2], DummySynapse(\"test2\"))\n",
    "\n",
    "tree_set(morph_comps, \"gbar_test1\", 123)\n",
    "tree_set(morph_comps, \"gbar_test2\", 123)\n",
    "\n",
    "subtree = tree_view(morph_comps, list(range(0,2)))\n",
    "subtree = tree_set(subtree, \"length\", 99.99) # <-- setting on views works\n",
    "morph_comps = merge_trees([morph_comps, subtree])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...\n",
       "1                                                    NaN\n",
       "2      [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...\n",
       "3                                                    NaN\n",
       "4                                                    NaN\n",
       "                             ...                        \n",
       "228                                                  NaN\n",
       "229                                                  NaN\n",
       "230                                                  NaN\n",
       "231                                                  NaN\n",
       "232                                                  NaN\n",
       "Name: nn_weights_test1, Length: 233, dtype: object"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph_comps.to_pandas()[0][\"nn_weights_test1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax_nodes, jax_edges = tree_to_pytree(morph_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testcase morph_3_types_single_point_soma.swc: 1, 1\n",
      "testcase morph_3_types.swc: 0, 0\n",
      "testcase morph_interrupted_soma.swc: 0, 0\n",
      "testcase morph_soma_both_ends.swc: 0, 0\n",
      "testcase morph_somatic_branchpoint.swc: 0, 0\n",
      "testcase morph_non_somatic_branchpoint.swc: 0, 0\n",
      "testcase morph_ca1_n120_single_point_soma.swc: 1, 1\n",
      "testcase morph_ca1_n120.swc: 0, 0\n",
      "testcase morph_l5pc_with_axon.swc: 0, 0\n",
      "testcase morph_allen_485574832.swc: 1, 1\n"
     ]
    }
   ],
   "source": [
    "from jaxley.io.graph import build_compartment_graph, to_swc_graph, _trace_branches\n",
    "\n",
    "testcases = [ \n",
    "\"morph_3_types_single_point_soma.swc\",\n",
    "\"morph_3_types.swc\",\n",
    "\"morph_interrupted_soma.swc\",\n",
    "\"morph_soma_both_ends.swc\",\n",
    "\"morph_somatic_branchpoint.swc\",\n",
    "\"morph_non_somatic_branchpoint.swc\", # no soma!\n",
    "\"morph_ca1_n120_single_point_soma.swc\",\n",
    "\"morph_ca1_n120.swc\",\n",
    "\"morph_l5pc_with_axon.swc\",\n",
    "\"morph_allen_485574832.swc\",\n",
    "]\n",
    "\n",
    "for i, testcase in enumerate(testcases):\n",
    "    jx_graph = to_swc_graph(\"../jaxley/tests/swc_files/\"+testcase)\n",
    "\n",
    "    morph_branches = list_branches(MorphTree.from_nx(jx_graph.copy()))\n",
    "    morph_branch_nodes = [np.sort(b) for b in morph_branches]\n",
    "\n",
    "    # do jx_trace after morph_traces, since jax_trace modifies the graph\n",
    "    jx_branches = _trace_branches(jx_graph.copy())[1]\n",
    "    jx_branch_nodes = [np.sort(np.unique(b[:, :-1])) for b in jx_branches]\n",
    "    if i in [0,6,9]: # single soma\n",
    "        jx_branch_nodes = [b-1 for b in jx_branch_nodes]\n",
    "\n",
    "    morph_eq_jx = []\n",
    "\n",
    "    for i, b in enumerate(jx_branch_nodes):\n",
    "        for j, mb in enumerate(morph_branch_nodes):\n",
    "            if len(b) == len(mb):\n",
    "                if np.allclose(b, mb):\n",
    "                    morph_eq_jx.append((i,j))\n",
    "                    break\n",
    "    if len(morph_eq_jx) > 0:\n",
    "        diff_morph_branches = [b for i, b in enumerate(morph_branch_nodes) if i not in np.array(morph_eq_jx)[:,1]]\n",
    "        diff_jx_branches = [b for j, b in enumerate(jx_branch_nodes) if j not in np.array(morph_eq_jx)[:,0]]\n",
    "    else:\n",
    "        print(\"No branches are equal\")\n",
    "        diff_morph_branches = morph_branch_nodes\n",
    "        diff_jx_branches = jx_branch_nodes\n",
    "    \n",
    "    # single soma handled differently and will lead to 1 diff branch\n",
    "    print(f\"testcase {testcase}: {len(diff_morph_branches)}, {len(diff_jx_branches)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from jaxley.io.graph import build_compartment_graph, to_swc_graph, _trace_branches\n",
    "\n",
    "# testcases = [ \n",
    "# \"morph_3_types_single_point_soma.swc\",\n",
    "# \"morph_3_types.swc\",\n",
    "# \"morph_interrupted_soma.swc\",\n",
    "# \"morph_soma_both_ends.swc\",\n",
    "# \"morph_somatic_branchpoint.swc\",\n",
    "# \"morph_non_somatic_branchpoint.swc\", # no soma!\n",
    "# \"morph_ca1_n120_single_point_soma.swc\",\n",
    "# \"morph_ca1_n120.swc\",\n",
    "# \"morph_l5pc_with_axon.swc\",\n",
    "# \"morph_allen_485574832.swc\",\n",
    "# ]\n",
    "\n",
    "# jx_graph = to_swc_graph(\"../jaxley/tests/swc_files/\"+testcases[2])\n",
    "\n",
    "# morph_branches = list_branches(MorphTree.from_nx(jx_graph.copy()))\n",
    "# morph_branch_nodes = [np.sort(b) for b in morph_branches]\n",
    "\n",
    "# # do jx_trace after morph_traces, since jax_trace modifies the graph\n",
    "# jx_branches = _trace_branches(jx_graph.copy())[1]\n",
    "# jx_branch_nodes = [np.sort(np.unique(b[:, :-1])) for b in jx_branches]\n",
    "# # jx_branch_nodes = [b-1 for b in jx_branch_nodes]\n",
    "\n",
    "\n",
    "# morph_eq_jx = []\n",
    "\n",
    "# for i, b in enumerate(jx_branch_nodes):\n",
    "#     for j, mb in enumerate(morph_branch_nodes):\n",
    "#         if len(b) == len(mb):\n",
    "#             if np.allclose(b, mb):\n",
    "#                 morph_eq_jx.append((i,j))\n",
    "#                 break\n",
    "# if len(morph_eq_jx) > 0:\n",
    "#     diff_morph_branches = [b for i, b in enumerate(morph_branch_nodes) if i not in np.array(morph_eq_jx)[:,1]]\n",
    "#     diff_jx_branches = [b for j, b in enumerate(jx_branch_nodes) if j not in np.array(morph_eq_jx)[:,0]]\n",
    "# else:\n",
    "#     print(\"No branches are equal\")\n",
    "#     diff_morph_branches = morph_branch_nodes\n",
    "#     diff_jx_branches = jx_branch_nodes\n",
    "\n",
    "# jx_subgraph = jx_graph.subgraph(np.unique(np.hstack(diff_morph_branches)))\n",
    "\n",
    "# # Get node positions and colors\n",
    "# pos = {node: (jx_subgraph.nodes[node]['x'], jx_subgraph.nodes[node]['y']) for node in jx_subgraph.nodes()}\n",
    "\n",
    "# # Create figure with 1x3 subplots\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# # Plot 1: Node indices\n",
    "# node_colors = [jx_subgraph.nodes[node]['id'] for node in jx_subgraph.nodes()]\n",
    "# nx.draw(jx_subgraph, pos=pos, node_color=node_colors, cmap='viridis', with_labels=True, ax=axes[0])\n",
    "# axes[0].set_title('Node Indices')\n",
    "\n",
    "# # Plot 2: JX branches\n",
    "# node_colors = np.zeros(len(jx_subgraph.nodes()))\n",
    "# for i, branch in enumerate(diff_jx_branches):\n",
    "#     node_colors[np.isin(list(jx_subgraph.nodes()), branch)] = i + 1\n",
    "# nx.draw(jx_subgraph, pos=pos, node_color=node_colors, cmap='tab10', with_labels=True, ax=axes[1])\n",
    "# axes[1].set_title('JX Branches')\n",
    "\n",
    "# # Plot 3: Morph branches\n",
    "# node_colors = np.zeros(len(jx_subgraph.nodes()))\n",
    "# for i, branch in enumerate(diff_morph_branches):\n",
    "#     node_colors[np.isin(list(jx_subgraph.nodes()), branch)] = i + 1\n",
    "# nx.draw(jx_subgraph, pos=pos, node_color=node_colors, cmap='tab10', with_labels=True, ax=axes[2])\n",
    "# axes[2].set_title('Morph Branches')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
