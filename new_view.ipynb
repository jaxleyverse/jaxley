{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from jax import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "config.update(\"jax_platform_name\", \"cpu\")\n",
    "\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\".8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jaxley as jx\n",
    "from jaxley.channels import HH\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import jax.numpy as jnp\n",
    "from jaxley.utils.cell_utils import interpolate_xyz, loc_of_index\n",
    "from copy import deepcopy\n",
    "from jaxley.utils.cell_utils import v_interp\n",
    "\n",
    "from jaxley.connect import connect\n",
    "from jaxley.synapses import IonotropicSynapse, TestSynapse\n",
    "from jaxley.utils.misc_utils import concat_and_ignore_empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another API idea\n",
    "\n",
    "branch = comp + comp + comp + comp\n",
    "branch += comp\n",
    "\n",
    "cell = branch + [branch + branch]\n",
    "cell += branch\n",
    "\n",
    "net = cell + [cell + cell]\n",
    "net += cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change base nodes\n",
    "# TODO: change inds to global inds in existing\n",
    "# TODO: replace comp_index with self._in_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyModule:\n",
    "    def __init__(self, module):\n",
    "        self.nseg = module.nseg\n",
    "        self.total_nbranches = 0\n",
    "        self.nbranches_per_cell = module.nbranches_per_cell\n",
    "        \n",
    "\n",
    "        self.nodes = module.nodes\n",
    "        \n",
    "        self.cumsum_nbranches = module.cumsum_nbranches\n",
    "\n",
    "        self.comb_parents = module.comb_parents\n",
    "\n",
    "        self.initialized_morph = module.initialized_morph\n",
    "        self.initialized_syns = module.initialized_syns\n",
    "\n",
    "        self.synapses = module.synapses\n",
    "        self.synapse_param_names = module.synapse_param_names\n",
    "        self.synapse_state_names = module.synapse_state_names\n",
    "        self.synapse_names = module.synapse_names\n",
    "        \n",
    "        self.channels = module.channels\n",
    "        self.membrane_current_names = module.membrane_current_names\n",
    "        \n",
    "        self.indices_set_by_trainables = module.indices_set_by_trainables\n",
    "        self.trainable_params = module.trainable_params\n",
    "        self.allow_make_trainable = module.allow_make_trainable\n",
    "        self.num_trainable_params = module.num_trainable_params\n",
    "        \n",
    "        self.recordings = module.recordings\n",
    "        self.externals = module.externals\n",
    "        self.external_inds = module.external_inds\n",
    "        self.xyzr = module.xyzr\n",
    "        \n",
    "        # different or modified from original module implementation\n",
    "        self.groups = {}\n",
    "        self.edges = pd.DataFrame(columns=[f\"{scope}_{lvl}_index\" for lvl in [\"pre_comp\", \"pre_branch\", \"pre_cell\", \"post_comp\", \"post_branch\", \"post_cell\"] for scope in [\"global\", \"local\"]]+[\"pre_locs\", \"post_locs\", \"type\", \"type_ind\"])\n",
    "        self._in_view = self.nodes.index.to_numpy()\n",
    "        self.nodes[\"controlled_by_param\"] = 0\n",
    "        self._scope = \"local\" # defaults to local scope\n",
    "        self.__class__.__name__ = module.__class__.__name__ # HOTFIX\n",
    "\n",
    "        # self.debug_states = module.debug_states\n",
    "\n",
    "        self._update_local_indices()\n",
    "        self.base = self\n",
    "\n",
    "    def _update_local_indices(self) -> pd.DataFrame:\n",
    "        idx_cols = [\"global_comp_index\", \"global_branch_index\", \"global_cell_index\"]\n",
    "        self.nodes.rename(\n",
    "            columns={col.replace(\"global_\", \"\"): col for col in idx_cols}, inplace=True\n",
    "        )\n",
    "        idcs = self.nodes[idx_cols]\n",
    "\n",
    "        def reindex_a_by_b(df, a, b):\n",
    "            df.loc[:, a] = df.groupby(b)[a].rank(method=\"dense\").astype(int) - 1\n",
    "            return df\n",
    "\n",
    "        idcs = reindex_a_by_b(idcs, idx_cols[1], idx_cols[2])\n",
    "        idcs = reindex_a_by_b(idcs, idx_cols[0], idx_cols[1:])\n",
    "        idcs.columns = [col.replace(\"global\", \"local\") for col in idx_cols]\n",
    "        self.nodes[[\"local_comp_index\", \"local_branch_index\", \"local_cell_index\"]] = (\n",
    "            idcs[[\"local_comp_index\", \"local_branch_index\", \"local_cell_index\"]]\n",
    "        )\n",
    "        # TODO: place indices at the front of the dataframe\n",
    "\n",
    "    def _reformat_index(self, idx):\n",
    "        idx = np.array([], dtype=int) if idx is None else idx\n",
    "        idx = np.array([idx]) if isinstance(idx, (int, np.int64)) else idx\n",
    "        idx = np.array(idx) if isinstance(idx, (list,range)) else idx\n",
    "        idx = np.arange(len(self._in_view) + 1)[idx] if isinstance(idx, slice) else idx\n",
    "        if isinstance(idx, str):\n",
    "            assert idx == \"all\", \"Only 'all' is allowed\"\n",
    "            idx = np.arange(len(self._in_view) + 1)\n",
    "        assert isinstance(idx, np.ndarray), \"Invalid type\"\n",
    "        assert idx.dtype == np.int64, \"Invalid dtype\"\n",
    "        return idx.reshape(-1)\n",
    "\n",
    "    def _set_controlled_by_param(self, key):\n",
    "        if key in [\"comp\", \"branch\", \"cell\"]:\n",
    "            self.nodes[\"controlled_by_param\"] = self.nodes[f\"global_{key}_index\"]\n",
    "            self.edges[\"controlled_by_param\"] = self.edges[f\"global_pre_{key}_index\"]\n",
    "        else:\n",
    "            self.nodes[\"controlled_by_param\"] = 0\n",
    "            self.edges[\"controlled_by_param\"] = 0\n",
    "\n",
    "    def at(self, idx, sorted=False):\n",
    "        idx = self._reformat_index(idx)\n",
    "        new_indices = self._in_view[idx]\n",
    "        new_indices = np.sort(new_indices) if sorted else new_indices\n",
    "        return View(self, at=new_indices)\n",
    "\n",
    "    def set(self, key: str, val: Union[float, jnp.ndarray]):\n",
    "        \"\"\"Set parameter of module (or its view) to a new value.\n",
    "\n",
    "        Note that this function can not be called within `jax.jit` or `jax.grad`.\n",
    "        Instead, it should be used set the parameters of the module **before** the\n",
    "        simulation. Use `.data_set()` to set parameters during `jax.jit` or\n",
    "        `jax.grad`.\n",
    "\n",
    "        Args:\n",
    "            key: The name of the parameter to set.\n",
    "            val: The value to set the parameter to. If it is `jnp.ndarray` then it\n",
    "                must be of shape `(len(num_compartments))`.\n",
    "        \"\"\"\n",
    "        if key in self.nodes.columns:\n",
    "            not_nan = ~self.nodes[key].isna()\n",
    "            self.base.nodes.loc[self._in_view[not_nan], key] = val\n",
    "        elif key in self.edges.columns:\n",
    "            not_nan = ~self.edges[key].isna()\n",
    "            self.base.edges.loc[self._edges_in_view[not_nan], key] = val\n",
    "        else:\n",
    "            raise KeyError(f\"Key '{key}' not found in nodes or edges\")\n",
    "\n",
    "    def set_scope(self, scope):\n",
    "        self._scope = scope\n",
    "\n",
    "    def scope(self, scope):\n",
    "        view = self.view\n",
    "        view.set_scope(scope)\n",
    "        return view\n",
    "    \n",
    "    def _at_level(self, level: str, idx):\n",
    "        idx = self._reformat_index(idx)\n",
    "        where = self.nodes[self._scope+f\"_{level}_index\"].isin(idx)\n",
    "        inds = np.where(where)[0]\n",
    "        view = self.at(inds)\n",
    "        view._set_controlled_by_param(level)\n",
    "        return view\n",
    "\n",
    "    def cell(self, idx):\n",
    "        return self._at_level(\"cell\", idx)\n",
    "    \n",
    "    def branch(self, idx):\n",
    "        return self._at_level(\"branch\", idx)\n",
    "    \n",
    "    def comp(self, idx):\n",
    "        return self._at_level(\"comp\", idx)\n",
    "    \n",
    "    def loc(self, at: float):\n",
    "        comp_edges = np.linspace(0, 1, self.base.nseg+1)\n",
    "        idx = np.digitize(at, comp_edges)\n",
    "        view = self.comp(idx)\n",
    "        return view\n",
    "        \n",
    "    def add_to_group(self, group_name: str):\n",
    "        \"\"\"Add a view of the module to a group.\n",
    "\n",
    "        Groups can then be indexed. For example:\n",
    "        ```python\n",
    "        net.cell(0).add_to_group(\"excitatory\")\n",
    "        net.excitatory.set(\"radius\", 0.1)\n",
    "        ```\n",
    "\n",
    "        Args:\n",
    "            group_name: The name of the group.\n",
    "        \"\"\"\n",
    "        self.base.groups[group_name] = self._in_view\n",
    "\n",
    "    def get_parameters(self) -> List[Dict[str, jnp.ndarray]]:\n",
    "        \"\"\"Get all trainable parameters.\n",
    "\n",
    "        The returned parameters should be passed to `jx.integrate(..., params=params).\n",
    "\n",
    "        Returns:\n",
    "            A list of all trainable parameters in the form of\n",
    "                [{\"gNa\": jnp.array([0.1, 0.2, 0.3])}, ...].\n",
    "        \"\"\"\n",
    "        return self.trainable_params\n",
    "\n",
    "    def __getattr__(self, key):\n",
    "        if key.startswith(\"__\"):\n",
    "            return super().__getattribute__(key)\n",
    "        \n",
    "        if key in self.base.groups:\n",
    "            view = self.at(self.groups[key]) if key in self.groups else self.at(None)\n",
    "            view._set_controlled_by_param(key)\n",
    "            return view\n",
    "        \n",
    "        if key in [c._name for c in self.base.channels]:\n",
    "            channel_names = [c._name for c in self.channels]\n",
    "            inds = self.nodes.index[self.nodes[key]].to_numpy()\n",
    "            view = self.at(inds) if key in channel_names else self.at(None)\n",
    "            view._set_controlled_by_param(key)\n",
    "            return view\n",
    "\n",
    "        if key in self.base.synapse_names:\n",
    "            # if the same 2 nodes are connected by 2 different synapses,\n",
    "            # module.SynapseA.edges will still contain both synapses\n",
    "            # since view filters based on index ONLY. Returning only the row\n",
    "            # that contains SynapseA is not possible currently. For setting\n",
    "            # synapse parameters this has no effect however.\n",
    "            has_syn = self.edges[\"type\"] == key\n",
    "            where = has_syn, [\"global_pre_comp_index\", \"global_post_comp_index\"]\n",
    "            comp_inds_in_view = pd.unique(self.edges.loc[where].values.ravel(\"K\"))\n",
    "            inds = np.where(self.nodes[\"global_comp_index\"].isin(comp_inds_in_view))[0]\n",
    "            view = self.at(inds) if key in self.synapse_names else self.at(None)\n",
    "            view._set_controlled_by_param(key)\n",
    "            return view\n",
    "        \n",
    "    def delete_trainables(self):\n",
    "        \"\"\"Removes all trainable parameters from the module.\"\"\"\n",
    "        self.base.indices_set_by_trainables = []\n",
    "        self.base.trainable_params = []\n",
    "        self.base.num_trainable_params = 0\n",
    "\n",
    "    def delete_recordings(self):\n",
    "        \"\"\"Removes all recordings from the module.\"\"\"\n",
    "        self.base.recordings = pd.DataFrame().from_dict({})\n",
    "\n",
    "    def show(\n",
    "        self,\n",
    "        param_names: Optional[Union[str, List[str]]] = None,  # TODO.\n",
    "        *,\n",
    "        indices: bool = True,\n",
    "        params: bool = True,\n",
    "        states: bool = True,\n",
    "        channel_names: Optional[List[str]] = None,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Print detailed information about the Module or a view of it.\n",
    "\n",
    "        Args:\n",
    "            param_names: The names of the parameters to show. If `None`, all parameters\n",
    "                are shown. NOT YET IMPLEMENTED.\n",
    "            indices: Whether to show the indices of the compartments.\n",
    "            params: Whether to show the parameters of the compartments.\n",
    "            states: Whether to show the states of the compartments.\n",
    "            channel_names: The names of the channels to show. If `None`, all channels are\n",
    "                shown.\n",
    "\n",
    "        Returns:\n",
    "            A `pd.DataFrame` with the requested information.\n",
    "        \"\"\"\n",
    "        nodes = self.nodes.copy()  # prevents this from being edited\n",
    "\n",
    "        cols = []\n",
    "        inds = [\"comp_index\", \"branch_index\", \"cell_index\"]\n",
    "        scopes = [\"local\", \"global\"]\n",
    "        cols += (\n",
    "            [f\"{scope}_{idx}\" for idx in inds for scope in scopes] if indices else []\n",
    "        )\n",
    "        cols += [ch._name for ch in self.channels] if channel_names else []\n",
    "        cols += (\n",
    "            sum([list(ch.channel_params) for ch in self.channels], []) if params else []\n",
    "        )\n",
    "        cols += (\n",
    "            sum([list(ch.channel_states) for ch in self.channels], []) if states else []\n",
    "        )\n",
    "\n",
    "        if not param_names is None:\n",
    "            cols = (\n",
    "                [c for c in cols if c in param_names] if params else list(param_names)\n",
    "            )\n",
    "\n",
    "        return nodes[cols]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        levels = [\"network\", \"cell\", \"branch\", \"comp\"]\n",
    "        module = self.base.__class__.__name__.lower()  #\n",
    "        module = \"comp\" if module == \"compartment\" else module\n",
    "\n",
    "        children = levels[levels.index(module) + 1 :]\n",
    "        index = index if isinstance(index, tuple) else (index,)\n",
    "        view = self\n",
    "        for i, child in enumerate(children):\n",
    "            view = view._at_level(child, index[i])\n",
    "        return view\n",
    "    \n",
    "    def _iter_level(self, level):\n",
    "        col = self._scope + f\"_{level}_index\"\n",
    "        idxs = self.nodes[col].unique()\n",
    "        for idx in idxs:\n",
    "            yield self._at_level(level, idx)\n",
    "    \n",
    "    @property\n",
    "    def cells(self):\n",
    "        yield from self._iter_level(\"cell\")\n",
    "    \n",
    "    @property\n",
    "    def branches(self):\n",
    "        yield from self._iter_level(\"branch\")\n",
    "\n",
    "    @property\n",
    "    def comps(self):\n",
    "        yield from self._iter_level(\"comp\")    \n",
    "\n",
    "    @property\n",
    "    def shape(self) -> Tuple[int]:\n",
    "        \"\"\"Returns the number of submodules contained in a module.\n",
    "\n",
    "        ```\n",
    "        network.shape = (num_cells, num_branches, num_compartments)\n",
    "        cell.shape = (num_branches, num_compartments)\n",
    "        branch.shape = (num_compartments,)\n",
    "        ```\"\"\"\n",
    "        cols = [\"global_cell_index\", \"global_branch_index\", \"global_comp_index\"]\n",
    "        raw_shape = self.nodes[cols].nunique().to_list()\n",
    "\n",
    "        # ensure (net.shape -> dim=3, cell.shape -> dim=2, branch.shape -> dim=1, comp.shape -> dim=0)\n",
    "        levels = [\"network\", \"cell\", \"branch\", \"comp\"]\n",
    "        module = self.base.__class__.__name__.lower()\n",
    "        module = \"comp\" if module == \"compartment\" else module\n",
    "        shape = tuple(raw_shape[levels.index(module) :])\n",
    "        return shape\n",
    "    \n",
    "    def copy(self, reset_index=False, as_module=False):\n",
    "        view = deepcopy(self)\n",
    "        # TODO: add reset_index, i.e. for parents, nodes, edges etc. such that they\n",
    "        # start from 0/-1 and are contiguous\n",
    "        if as_module:\n",
    "            # TODO: initialize a new module with the same attributes\n",
    "            pass\n",
    "        return view\n",
    "    \n",
    "    @property\n",
    "    def view(self):\n",
    "        return View(self, self._in_view)\n",
    "\n",
    "    def vis(\n",
    "        self,\n",
    "        ax: Optional[Axes] = None,\n",
    "        col: str = \"k\",\n",
    "        dims: Tuple[int] = (0, 1),\n",
    "        type: str = \"line\",\n",
    "        morph_plot_kwargs: Dict = {},\n",
    "    ) -> Axes:\n",
    "        \"\"\"Visualize the module.\n",
    "\n",
    "        Args:\n",
    "            ax: An axis into which to plot.\n",
    "            col: The color for all branches.\n",
    "            dims: Which dimensions to plot. 1=x, 2=y, 3=z coordinate. Must be a tuple of\n",
    "                two of them.\n",
    "            morph_plot_kwargs: Keyword arguments passed to the plotting function.\n",
    "        \"\"\"\n",
    "        branches_inds = self.nodes[\"branch_index\"].to_numpy()\n",
    "        coords = []\n",
    "        for branch_ind in branches_inds:\n",
    "            assert not np.any(\n",
    "                np.isnan(self.xyzr[branch_ind][:, dims])\n",
    "            ), \"No coordinates available. Use `vis(detail='point')` or run `.compute_xyz()` before running `.vis()`.\"\n",
    "            coords.append(self.xyzr[branch_ind])\n",
    "\n",
    "        ax = plot_morph(\n",
    "            coords,\n",
    "            dims=dims,\n",
    "            col=col,\n",
    "            ax=ax,\n",
    "            type=type,\n",
    "            morph_plot_kwargs=morph_plot_kwargs,\n",
    "        )\n",
    "\n",
    "        return ax\n",
    "\n",
    "    def record(self, state, verbose=True):\n",
    "        new_recs = pd.DataFrame(self._in_view, columns=[\"rec_index\"])\n",
    "        new_recs[\"state\"] = state\n",
    "        self.base.recordings = pd.concat([self.base.recordings, new_recs])\n",
    "        has_duplicates = self.base.recordings.duplicated()\n",
    "        self.base.recordings = self.base.recordings.loc[~has_duplicates]\n",
    "        if verbose:\n",
    "            print(f\"Added {len(self._in_view)-sum(has_duplicates)} recordings. See `.recordings` for details.\")\n",
    "\n",
    "    def insert(self, channel):\n",
    "        name = channel._name\n",
    "\n",
    "        # Channel does not yet exist in the `jx.Module` at all.\n",
    "        if name not in [c._name for c in self.base.channels]:\n",
    "            self.base.channels.append(channel)\n",
    "            self.base.nodes[name] = (\n",
    "                False  # Previous columns do not have the new channel.\n",
    "            )\n",
    "\n",
    "        if channel.current_name not in self.base.membrane_current_names:\n",
    "            self.base.membrane_current_names.append(channel.current_name)\n",
    "\n",
    "        # Add a binary column that indicates if a channel is present.\n",
    "        self.base.nodes.loc[self._in_view, name] = True\n",
    "\n",
    "        # Loop over all new parameters, e.g. gNa, eNa.\n",
    "        for key in channel.channel_params:\n",
    "            self.base.nodes.loc[self._in_view, key] = channel.channel_params[key]\n",
    "\n",
    "        # Loop over all new parameters, e.g. gNa, eNa.\n",
    "        for key in channel.channel_states:\n",
    "            self.base.nodes.loc[self._in_view, key] = channel.channel_states[key]\n",
    "    \n",
    "    def stimulate(self, current: Optional[jnp.ndarray] = None, verbose: bool = True):\n",
    "        \"\"\"Insert a stimulus into the compartment.\n",
    "\n",
    "        current must be a 1d array or have batch dimension of size `(num_compartments, )`\n",
    "        or `(1, )`. If 1d, the same stimulus is added to all compartments.\n",
    "\n",
    "        This function cannot be run during `jax.jit` and `jax.grad`. Because of this,\n",
    "        it should only be used for static stimuli (i.e., stimuli that do not depend\n",
    "        on the data and that should not be learned). For stimuli that depend on data\n",
    "        (or that should be learned), please use `data_stimulate()`.\n",
    "\n",
    "        Args:\n",
    "            current: Current in `nA`.\n",
    "        \"\"\"\n",
    "        self._external_input(\"i\", current, verbose=verbose)\n",
    "\n",
    "    def clamp(self, state_name: str, state_array: jnp.ndarray, verbose: bool = True):\n",
    "        \"\"\"Clamp a state to a given value across specified compartments.\n",
    "\n",
    "        Args:\n",
    "            state_name: The name of the state to clamp.\n",
    "            state_array (jnp.nd: Array of values to clamp the state to.\n",
    "            verbose : If True, prints details about the clamping.\n",
    "\n",
    "        This function sets external states for the compartments.\n",
    "        \"\"\"\n",
    "        if state_name not in self.nodes.columns:\n",
    "            raise KeyError(f\"{state_name} is not a recognized state in this module.\")\n",
    "        self._external_input(state_name, state_array, self.nodes, verbose=verbose)\n",
    "\n",
    "    def _external_input(\n",
    "        self,\n",
    "        key: str,\n",
    "        values: Optional[jnp.ndarray],\n",
    "        verbose: bool = True,\n",
    "    ):\n",
    "        values = values if values.ndim == 2 else jnp.expand_dims(values, axis=0)\n",
    "        batch_size = values.shape[0]\n",
    "        num_inserted = len(self._in_view)\n",
    "        is_multiple = num_inserted == batch_size\n",
    "        values = (\n",
    "            values if is_multiple else jnp.repeat(values, len(self._in_view), axis=0)\n",
    "        )\n",
    "        assert batch_size in [\n",
    "            1,\n",
    "            num_inserted,\n",
    "        ], \"Number of comps and stimuli do not match.\"\n",
    "\n",
    "        if key in self.base.externals.keys():\n",
    "            self.base.externals[key] = jnp.concatenate(\n",
    "                [self.base.externals[key], values]\n",
    "            )\n",
    "            self.base.external_inds[key] = jnp.concatenate(\n",
    "                [self.base.external_inds[key], self._in_view]\n",
    "            )\n",
    "        else:\n",
    "            self.base.externals[key] = values\n",
    "            self.base.external_inds[key] = self._in_view\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"Added {num_inserted} external_states. See `.externals` for details.\"\n",
    "            )\n",
    "\n",
    "    def data_stimulate(self, current, data_stimuli, verbose=False):\n",
    "        current = current if current.ndim == 2 else jnp.expand_dims(current, axis=0)\n",
    "        batch_size = current.shape[0]\n",
    "        num_inserted = len(self._in_view)\n",
    "        is_multiple = num_inserted == batch_size\n",
    "        current = current if is_multiple else jnp.repeat(current, num_inserted, axis=0)\n",
    "        assert batch_size in [1, num_inserted], \"Number of comps and stimuli do not match.\"\n",
    "\n",
    "        if data_stimuli is not None:\n",
    "            currents = data_stimuli[0]\n",
    "            inds = data_stimuli[1]\n",
    "        else:\n",
    "            currents = None\n",
    "            inds = pd.DataFrame().from_dict({})\n",
    "\n",
    "        # Same as in `.stimulate()`.\n",
    "        if currents is not None:\n",
    "            currents = jnp.concatenate([currents, current])\n",
    "        else:\n",
    "            currents = current\n",
    "        inds = pd.concat([inds, self._in_view])\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Added {num_inserted} stimuli.\")\n",
    "\n",
    "        return (currents, inds)\n",
    "\n",
    "    def data_set(\n",
    "        self,\n",
    "        key: str,\n",
    "        val: Union[float, jnp.ndarray],\n",
    "        param_state: Optional[List[Dict]],\n",
    "    ):\n",
    "        \"\"\"Set parameter of module (or its view) to a new value within `jit`.\n",
    "\n",
    "        Args:\n",
    "            key: The name of the parameter to set.\n",
    "            val: The value to set the parameter to. If it is `jnp.ndarray` then it\n",
    "                must be of shape `(len(num_compartments))`.\n",
    "            param_state: State of the setted parameters, internally used such that this\n",
    "                function does not modify global state.\n",
    "        \"\"\"\n",
    "        # Note: `data_set` does not support arrays for `val`.\n",
    "        if key in self.nodes.columns:\n",
    "            not_nan = ~self.nodes[key].isna()\n",
    "            added_param_state = [\n",
    "                {\n",
    "                    \"indices\": np.atleast_2d(self._in_view[not_nan]),\n",
    "                    \"key\": key,\n",
    "                    \"val\": jnp.atleast_1d(jnp.asarray(val)),\n",
    "                }\n",
    "            ]\n",
    "            if param_state is not None:\n",
    "                param_state += added_param_state\n",
    "            else:\n",
    "                param_state = added_param_state\n",
    "        else:\n",
    "            raise KeyError(\"Key not recognized.\")\n",
    "        return param_state\n",
    "\n",
    "    def move(\n",
    "        self, x: float = 0.0, y: float = 0.0, z: float = 0.0, update_nodes: bool = True\n",
    "    ):\n",
    "        \"\"\"Move cells or networks by adding to their (x, y, z) coordinates.\n",
    "\n",
    "        This function is used only for visualization. It does not affect the simulation.\n",
    "\n",
    "        Args:\n",
    "            x: The amount to move in the x direction in um.\n",
    "            y: The amount to move in the y direction in um.\n",
    "            z: The amount to move in the z direction in um.\n",
    "            update_nodes: Whether `.nodes` should be updated or not. Setting this to\n",
    "                `False` largely speeds up moving, especially for big networks, but\n",
    "                `.nodes` or `.show` will not show the new xyz coordinates.\n",
    "        \"\"\"\n",
    "        indizes = self.nodes[\"global_branch_index\"].unique()\n",
    "        for i in indizes:\n",
    "            self.base.xyzr[i][:, :3] += np.array([x, x, y])\n",
    "        if update_nodes:\n",
    "            self._update_nodes_with_xyz()\n",
    "\n",
    "    def move_to(\n",
    "        self,\n",
    "        x: Union[float, np.ndarray] = 0.0,\n",
    "        y: Union[float, np.ndarray] = 0.0,\n",
    "        z: Union[float, np.ndarray] = 0.0,\n",
    "        update_nodes: bool = True,\n",
    "    ):\n",
    "        \"\"\"Move cells or networks to a location (x, y, z).\n",
    "\n",
    "        If x, y, and z are floats, then the first compartment of the first branch\n",
    "        of the first cell is moved to that float coordinate, and everything else is\n",
    "        shifted by the difference between that compartment's previous coordinate and\n",
    "        the new float location.\n",
    "\n",
    "        If x, y, and z are arrays, then they must each have a length equal to the number\n",
    "        of cells being moved. Then the first compartment of the first branch of each\n",
    "        cell is moved to the specified location.\n",
    "\n",
    "        Args:\n",
    "            update_nodes: Whether `.nodes` should be updated or not. Setting this to\n",
    "                `False` largely speeds up moving, especially for big networks, but\n",
    "                `.nodes` or `.show` will not show the new xyz coordinates.\n",
    "        \"\"\"\n",
    "        # Test if any coordinate values are NaN which would greatly affect moving\n",
    "        if np.any(np.concatenate(self.xyzr, axis=0)[:, :3] == np.nan):\n",
    "            raise ValueError(\n",
    "                \"NaN coordinate values detected. Shift amounts cannot be computed. Please run compute_xyzr() or assign initial coordinate values.\"\n",
    "            )\n",
    "\n",
    "        indizes = self.nodes[\"global_branch_index\"].unique()\n",
    "        move_by = (\n",
    "            np.array([x, y, z]).T - self.xyzr[0][0, :3]\n",
    "        )  # move with respect to root idx\n",
    "\n",
    "        for idx in indizes:\n",
    "            self.base.xyzr[idx][:, :3] += move_by\n",
    "        if update_nodes:\n",
    "            self._update_nodes_with_xyz()\n",
    "\n",
    "    def rotate(\n",
    "        self, degrees: float, rotation_axis: str = \"xy\", update_nodes: bool = True\n",
    "    ):\n",
    "        \"\"\"Rotate jaxley modules clockwise. Used only for visualization.\n",
    "\n",
    "        This function is used only for visualization. It does not affect the simulation.\n",
    "\n",
    "        Args:\n",
    "            degrees: How many degrees to rotate the module by.\n",
    "            rotation_axis: Either of {`xy` | `xz` | `yz`}.\n",
    "        \"\"\"\n",
    "        degrees = degrees / 180 * np.pi\n",
    "        if rotation_axis == \"xy\":\n",
    "            dims = [0, 1]\n",
    "        elif rotation_axis == \"xz\":\n",
    "            dims = [0, 2]\n",
    "        elif rotation_axis == \"yz\":\n",
    "            dims = [1, 2]\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        rotation_matrix = np.asarray(\n",
    "            [[np.cos(degrees), np.sin(degrees)], [-np.sin(degrees), np.cos(degrees)]]\n",
    "        )\n",
    "        indizes = self.nodes[\"global_branch_index\"].unique()\n",
    "        for i in indizes:\n",
    "            rot = np.dot(rotation_matrix, self.base.xyzr[i][:, dims].T).T\n",
    "            self.base.xyzr[i][:, dims] = rot\n",
    "        if update_nodes:\n",
    "            self._update_nodes_with_xyz()\n",
    "\n",
    "    def _update_nodes_with_xyz(self):\n",
    "        \"\"\"Add xyz coordinates of compartment centers to nodes.\n",
    "\n",
    "        Centers are the midpoint between the comparment endpoints on the morphology\n",
    "        as defined by xyzr.\n",
    "\n",
    "        Note: For sake of performance, interpolation is not done for each branch\n",
    "        individually, but only once along a concatenated (and padded) array of all branches.\n",
    "        This means for nsegs = [2,4] and normalized cum_branch_lens of [[0,1],[0,1]] we would\n",
    "        interpolate xyz at the locations comp_ends = [[0,0.5,1], [0,0.25,0.5,0.75,1]],\n",
    "        where 0 is the start of the branch and 1 is the end point at the full branch_len.\n",
    "        To avoid do this in one go we set comp_ends = [0,0.5,1,2,2.25,2.5,2.75,3], and\n",
    "        norm_cum_branch_len = [0,1,2,3] incrememting and also padding them by 1 to\n",
    "        avoid overlapping branch_lens i.e. norm_cum_branch_len = [0,1,1,2] for only\n",
    "        incrementing.\n",
    "        \"\"\"\n",
    "        nsegs = (\n",
    "            self.nodes.groupby(\"global_branch_index\")[\"global_comp_index\"]\n",
    "            .nunique()\n",
    "            .to_numpy()\n",
    "        )\n",
    "\n",
    "        comp_ends = np.hstack(\n",
    "            [np.linspace(0, 1, nseg + 1) + 2 * i for i, nseg in enumerate(nsegs)]\n",
    "        )\n",
    "        comp_ends = comp_ends.reshape(-1)\n",
    "        cum_branch_lens = []\n",
    "        for i, xyzr in enumerate(self.xyzr):\n",
    "            branch_len = np.sqrt(np.sum(np.diff(xyzr[:, :3], axis=0) ** 2, axis=1))\n",
    "            cum_branch_len = np.cumsum(np.concatenate([np.array([0]), branch_len]))\n",
    "            max_len = cum_branch_len.max()\n",
    "            # add padding like above\n",
    "            cum_branch_len = cum_branch_len / (max_len if max_len > 0 else 1) + 2 * i\n",
    "            cum_branch_len[np.isnan(cum_branch_len)] = 0\n",
    "            cum_branch_lens.append(cum_branch_len)\n",
    "        cum_branch_lens = np.hstack(cum_branch_lens)\n",
    "        xyz = np.vstack(self.xyzr)[:, :3]\n",
    "        xyz = v_interp(comp_ends, cum_branch_lens, xyz).T\n",
    "        centers = (xyz[:-1] + xyz[1:]) / 2  # unaware of inter vs intra comp centers\n",
    "        cum_nsegs = np.cumsum(nsegs)\n",
    "        # this means centers between comps have to be removed here\n",
    "        between_comp_inds = (cum_nsegs + np.arange(len(cum_nsegs)))[:-1]\n",
    "        centers = np.delete(centers, between_comp_inds, axis=0)\n",
    "        self.base.nodes.loc[self._in_view, [\"x\", \"y\", \"z\"]] = centers\n",
    "        return centers, xyz\n",
    "    \n",
    "    def make_trainable(\n",
    "        self,\n",
    "        key: str,\n",
    "        init_val: Optional[Union[float, list]] = None,\n",
    "        verbose: bool = True,\n",
    "    ):\n",
    "        \"\"\"Make a parameter trainable.\n",
    "\n",
    "        If a parameter is made trainable, it will be returned by `get_parameters()`\n",
    "        and should then be passed to `jx.integrate(..., params=params)`.\n",
    "\n",
    "        Args:\n",
    "            key: Name of the parameter to make trainable.\n",
    "            init_val: Initial value of the parameter. If `float`, the same value is\n",
    "                used for every created parameter. If `list`, the length of the list has\n",
    "                to match the number of created parameters. If `None`, the current\n",
    "                parameter value is used and if parameter sharing is performed that the\n",
    "                current parameter value is averaged over all shared parameters.\n",
    "            verbose: Whether to print the number of parameters that are added and the\n",
    "                total number of parameters.\n",
    "        \"\"\"\n",
    "        assert (\n",
    "            self.allow_make_trainable\n",
    "        ), \"network.cell('all').make_trainable() is not supported. Use a for-loop over cells.\"\n",
    "\n",
    "        data = self.nodes if key in self.nodes.columns else None\n",
    "        data = self.edges if key in self.edges.columns else data\n",
    "        assert data is not None, f\"Key '{key}' not found in nodes or edges\"\n",
    "        not_nan = ~data[key].isna()\n",
    "        data = data.loc[not_nan]\n",
    "        assert (\n",
    "            len(data) > 0\n",
    "        ), \"No settable parameters found in the selected compartments.\"\n",
    "\n",
    "        grouped_view = data.groupby(\"controlled_by_param\")\n",
    "        # Because of this `x.index.values` we cannot support `make_trainable()` on\n",
    "        # the module level for synapse parameters (but only for `SynapseView`).\n",
    "        inds_of_comps = list(\n",
    "            grouped_view.apply(lambda x: x.index.values, include_groups=False)\n",
    "        )\n",
    "        indices_per_param = jnp.stack(inds_of_comps)\n",
    "        # Sorted inds are only used to infer the correct starting values.\n",
    "        param_vals = jnp.asarray(\n",
    "            [data.loc[inds, key].to_numpy() for inds in inds_of_comps]\n",
    "        )\n",
    "\n",
    "        # Set the value which the trainable parameter should take.\n",
    "        num_created_parameters = len(indices_per_param)\n",
    "        if init_val is not None:\n",
    "            if isinstance(init_val, float):\n",
    "                new_params = jnp.asarray([init_val] * num_created_parameters)\n",
    "            elif isinstance(init_val, list):\n",
    "                assert (\n",
    "                    len(init_val) == num_created_parameters\n",
    "                ), f\"len(init_val)={len(init_val)}, but trying to create {num_created_parameters} parameters.\"\n",
    "                new_params = jnp.asarray(init_val)\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"init_val must a float, list, or None, but it is a {type(init_val).__name__}.\"\n",
    "                )\n",
    "        else:\n",
    "            new_params = jnp.mean(param_vals, axis=1)\n",
    "        self.base.trainable_params.append({key: new_params})\n",
    "        self.base.indices_set_by_trainables.append(indices_per_param)\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"Number of newly added trainable parameters: {num_created_parameters}. Total number of trainable parameters: {self.num_trainable_params}\"\n",
    "            )\n",
    "\n",
    "    # THIS IS PART OF NETWORK\n",
    "    def _infer_synapse_type_ind(self, synapse_name):\n",
    "        syn_names = self.base.synapse_names\n",
    "        is_new_type = False if synapse_name in syn_names else True\n",
    "        type_ind = len(syn_names) if is_new_type else syn_names.index(synapse_name)\n",
    "        return type_ind, is_new_type\n",
    "    \n",
    "    def _update_synapse_state_names(self, synapse_type):\n",
    "        # (Potentially) update variables that track meta information about synapses.\n",
    "        self.base.synapse_names.append(synapse_type._name)\n",
    "        self.base.synapse_param_names += list(synapse_type.synapse_params.keys())\n",
    "        self.base.synapse_state_names += list(synapse_type.synapse_states.keys())\n",
    "        self.base.synapses.append(synapse_type)\n",
    "\n",
    "    def _append_multiple_synapses(self, pre, post, synapse_type):\n",
    "        # Add synapse types to the module and infer their unique identifier.\n",
    "        synapse_name = synapse_type._name\n",
    "        type_ind, is_new = self._infer_synapse_type_ind(synapse_name)\n",
    "        if is_new:  # synapse is not known\n",
    "            self._update_synapse_state_names(synapse_type)\n",
    "\n",
    "        index = len(self.base.edges)\n",
    "        post_loc = loc_of_index(post._comps_in_view, self.nseg)\n",
    "        pre_loc = loc_of_index(pre._comps_in_view, self.nseg)\n",
    "\n",
    "        # Define new synapses. Each row is one synapse.\n",
    "        cols = [\"comp_index\", \"branch_index\", \"cell_index\"]\n",
    "        pre_nodes = pre.nodes[[f\"{scope}_{col}\" for col in cols for scope in [\"local\", \"global\"]]]\n",
    "        pre_nodes.columns = [f\"{scope}_pre_{col}\" for col in cols for scope in [\"local\", \"global\"]]\n",
    "        post_nodes = post.nodes[[f\"{scope}_{col}\" for col in cols for scope in [\"local\", \"global\"]]]\n",
    "        post_nodes.columns = [f\"{scope}_post_{col}\" for col in cols for scope in [\"local\", \"global\"]]\n",
    "        new_rows = pd.concat([pre_nodes.reset_index(drop=True), post_nodes.reset_index(drop=True)], axis=1)\n",
    "        new_rows[\"type\"] = synapse_name\n",
    "        new_rows[\"type_ind\"] = type_ind\n",
    "        new_rows[\"pre_loc\"] = pre_loc\n",
    "        new_rows[\"post_loc\"] = post_loc\n",
    "        self.base.edges = concat_and_ignore_empty(\n",
    "            [self.base.edges, new_rows],\n",
    "            ignore_index=True, axis=0\n",
    "        )\n",
    "\n",
    "        indices = [idx for idx in range(index, index + len(pre_loc))]\n",
    "        self._add_params_to_edges(synapse_type, indices)\n",
    "\n",
    "    def _add_params_to_edges(self, synapse_type, indices):\n",
    "        # Add parameters and states to the `.edges` table.\n",
    "        for key, param_val in synapse_type.synapse_params.items():\n",
    "            self.base.edges.loc[indices, key] = param_val\n",
    "\n",
    "        # Update synaptic state array.\n",
    "        for key, state_val in synapse_type.synapse_states.items():\n",
    "            self.base.edges.loc[indices, key] = state_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(DummyModule):\n",
    "    def __init__(self, pointer, at = None):\n",
    "        # attrs with a static view\n",
    "        self._scope = pointer._scope\n",
    "        self.base = pointer.base\n",
    "        self.initialized_morph = pointer.initialized_morph\n",
    "        self.initialized_syns = pointer.initialized_syns\n",
    "        self.allow_make_trainable = pointer.allow_make_trainable\n",
    "        \n",
    "        # attrs affected by view\n",
    "        self.nseg = pointer.nseg\n",
    "        self._in_view = pointer._in_view if at is None else at\n",
    "\n",
    "        self.nodes = pointer.nodes.loc[self._in_view]\n",
    "        self.edges = pointer.edges.loc[self._edges_in_view]\n",
    "        self.xyzr = self._xyzr_in_view(pointer)\n",
    "        self.nseg = 1 if len(self.nodes) == 1 else pointer.nseg\n",
    "        self.total_nbranches = len(self._branches_in_view)\n",
    "        self.nbranches_per_cell = self._nbranches_per_cell_in_view()\n",
    "        self.cumsum_nbranches = np.cumsum(self.nbranches_per_cell)\n",
    "        self.comb_branches_in_each_level = pointer.comb_branches_in_each_level\n",
    "        self.branch_edges = pointer.branch_edges.loc[self._branch_edges_in_view]\n",
    "\n",
    "        self.synapse_names = np.unique(self.edges[\"type\"]).tolist()\n",
    "        self.synapses, self.synapse_param_names, self.synapse_state_names = self._synapses_in_view(pointer)\n",
    "\n",
    "        if pointer.recordings.empty:\n",
    "            self.recordings = pd.DataFrame()\n",
    "        else:\n",
    "            self.recordings = pointer.recordings.loc[pointer.recordings[\"rec_index\"].isin(self._comps_in_view)]\n",
    "        \n",
    "        self.channels = self._channels_in_view(pointer)\n",
    "        self.membrane_current_names = [c._name for c in self.channels]\n",
    "\n",
    "        self.indices_set_by_trainables, self.trainable_params = self._trainables_in_view()\n",
    "        self.num_trainable_params = np.sum([len(inds) for inds in self.indices_set_by_trainables])\n",
    "\n",
    "        self.comb_parents = self.base.comb_parents[self._branches_in_view]\n",
    "        self.externals, self.external_inds = self._externals_in_view()\n",
    "        self.groups = {k:np.intersect1d(v, self._in_view) for k,v in pointer.groups.items()} \n",
    "\n",
    "        #TODO:\n",
    "        # self.debug_states\n",
    "\n",
    "        if len(self.nodes) == 0:\n",
    "            raise ValueError(\"Nothing in view. Check your indices.\")\n",
    "        \n",
    "    def _externals_in_view(self):\n",
    "        externals_in_view = {}\n",
    "        external_inds_in_view = []\n",
    "        for (name, inds), data in zip(self.base.external_inds.items(), self.base.externals.values()):\n",
    "            in_view = np.isin(inds, self._in_view)\n",
    "            inds_in_view = inds[in_view]\n",
    "            if len(inds_in_view) > 0:\n",
    "                externals_in_view[name] = data[in_view]\n",
    "                external_inds_in_view.append(inds_in_view)\n",
    "        return externals_in_view, external_inds_in_view\n",
    "\n",
    "    def _trainables_in_view(self):\n",
    "        trainable_inds = self.base.indices_set_by_trainables\n",
    "        trainable_inds = np.unique(np.hstack([inds.reshape(-1) for inds in trainable_inds])) if len(trainable_inds) > 0 else []\n",
    "        trainable_inds_in_view = np.intersect1d(trainable_inds, self._in_view)\n",
    "        \n",
    "        índices_set_by_trainables_in_view = []\n",
    "        trainable_params_in_view = []\n",
    "        for inds, params in zip(self.base.indices_set_by_trainables, self.base.trainable_params):\n",
    "            in_view = np.isin(inds, trainable_inds_in_view)\n",
    "            \n",
    "            completely_in_view = in_view.all(axis=1)\n",
    "            índices_set_by_trainables_in_view.append(inds[completely_in_view])\n",
    "            trainable_params_in_view.append({k:v[completely_in_view] for k,v in params.items()})\n",
    "            \n",
    "            partially_in_view = in_view.any(axis=1) & ~completely_in_view\n",
    "            índices_set_by_trainables_in_view.append(inds[partially_in_view][in_view[partially_in_view]])\n",
    "            trainable_params_in_view.append({k:v[partially_in_view] for k,v in params.items()})\n",
    "\n",
    "        índices_set_by_trainables_in_view = [inds for inds in índices_set_by_trainables_in_view if len(inds) > 0]\n",
    "        trainable_params_in_view = [p for p in trainable_params_in_view if len(next(iter(p.values()))) > 0]\n",
    "        return índices_set_by_trainables_in_view, trainable_params_in_view\n",
    "\n",
    "    def _channels_in_view(self, pointer):\n",
    "        names = [name._name for name in pointer.channels]\n",
    "        channel_in_view = self.nodes[names].any(axis=0)\n",
    "        channel_in_view = channel_in_view[channel_in_view].index\n",
    "        return [c for c in pointer.channels if c._name in channel_in_view]\n",
    "        \n",
    "    def _synapses_in_view(self, pointer):\n",
    "        viewed_synapses = []\n",
    "        viewed_params = []\n",
    "        viewed_states = []\n",
    "        if not pointer.synapses is None:\n",
    "            for syn in pointer.synapses:\n",
    "                if syn is not None: # needed for recurive viewing\n",
    "                    in_view = syn._name in self.synapse_names\n",
    "                    viewed_synapses += [syn] if in_view else [None] # padded with None to keep indices consistent\n",
    "                    viewed_params += list(syn.synapse_params.keys()) if in_view else []\n",
    "                    viewed_states += list(syn.synapse_states.keys()) if in_view else []\n",
    "\n",
    "        return viewed_synapses, viewed_params, viewed_states\n",
    "        \n",
    "    def _nbranches_per_cell_in_view(self):\n",
    "        cell_nodes = self.nodes.groupby(\"global_cell_index\")\n",
    "        return cell_nodes[\"global_branch_index\"].nunique().to_numpy()       \n",
    "\n",
    "    def _xyzr_in_view(self, pointer):\n",
    "        prev_branch_inds = pointer._branches_in_view\n",
    "        viewed_branch_inds = self._branches_in_view\n",
    "        if prev_branch_inds is None:\n",
    "            xyzr = pointer.xyzr.copy() # copy to prevent editing original\n",
    "        else:\n",
    "            branches2keep = np.isin(prev_branch_inds, viewed_branch_inds)\n",
    "            branch_inds2keep = np.where(branches2keep)[0]\n",
    "            xyzr = [pointer.xyzr[i] for i in branch_inds2keep].copy()\n",
    "\n",
    "        # Currently viewing with `.loc` will show the closest compartment\n",
    "        # rather than the actual loc along the branch!\n",
    "        viewed_nseg_for_branch = self.nodes.groupby(\"global_branch_index\").size()\n",
    "        incomplete_inds = np.where(viewed_nseg_for_branch != self.base.nseg)[0]\n",
    "        incomplete_branch_inds = viewed_branch_inds[incomplete_inds]\n",
    "\n",
    "        cond = self.nodes[\"global_branch_index\"].isin(incomplete_branch_inds)\n",
    "        interp_inds = self.nodes.loc[cond]\n",
    "        local_inds_per_branch = interp_inds.groupby(\"global_branch_index\")[\"local_comp_index\"]\n",
    "        locs = [loc_of_index(inds.to_numpy(), self.base.nseg) for _, inds in local_inds_per_branch]\n",
    "        \n",
    "        for i, loc in zip(incomplete_inds, locs):\n",
    "            xyzr[i] = interpolate_xyz(loc, xyzr[i]).T\n",
    "        return xyzr\n",
    "\n",
    "    @property\n",
    "    def _nodes_in_view(self):\n",
    "        return self._in_view\n",
    "    \n",
    "    @property\n",
    "    def _branch_edges_in_view(self):\n",
    "        incl_branches = self.nodes[\"global_branch_index\"].unique()\n",
    "        pre = self.base.branch_edges[\"parent_branch_index\"].isin(incl_branches)\n",
    "        post = self.base.branch_edges[\"child_branch_index\"].isin(incl_branches)\n",
    "        viewed_branch_inds = self.base.branch_edges.index.to_numpy()[pre & post]\n",
    "        return viewed_branch_inds\n",
    "    \n",
    "    @property\n",
    "    def _edges_in_view(self):\n",
    "        incl_comps = self.nodes[\"global_comp_index\"].unique()\n",
    "        pre = self.base.edges[\"global_pre_comp_index\"].isin(incl_comps).to_numpy()\n",
    "        post = self.base.edges[\"global_post_comp_index\"].isin(incl_comps).to_numpy()\n",
    "        viewed_edge_inds = self.base.edges.index.to_numpy()[(pre & post).flatten()]\n",
    "        return viewed_edge_inds\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        # Delegate attribute access to the pointer if not found in View\n",
    "        return getattr(self.pointer, name)\n",
    "    \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, exc_traceback):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add test that asserts that every attr in view also has a corresponding attr in module\n",
    "# apart from a few allowed exceptions\n",
    "# this should trigger if new attrs are added to module that should potentially\n",
    "# be included in view if they need to be accessed in a specific way\n",
    "\n",
    "def test_view_attrs(module):\n",
    "    exceptions = [\"_scope\", \"_at\", \"view\"]\n",
    "\n",
    "    for name, attr in module.__dict__.items():\n",
    "        if name not in exceptions:\n",
    "            # check if attr is in view\n",
    "            assert hasattr(View(module, np.array([0,1])), name), f\"View missing attribute: {name}\"\n",
    "            # check if types match\n",
    "            assert type(getattr(module, name)) == type(getattr(View(module, np.array([0,1])), name), f\"Type mismatch: {name}\")\n",
    "\n",
    "#TODO replace global and local cell indexes with just global_cell_index\n",
    "\n",
    "\n",
    "def connect(\n",
    "    pre: \"CompartmentView\",\n",
    "    post: \"CompartmentView\",\n",
    "    synapse_type: \"Synapse\",\n",
    "):\n",
    "    \"\"\"Connect two compartments with a chemical synapse.\n",
    "\n",
    "    The pre- and postsynaptic compartments must be different compartments of the\n",
    "    same network.\n",
    "\n",
    "    Args:\n",
    "        pre: View of the presynaptic compartment.\n",
    "        post: View of the postsynaptic compartment.\n",
    "        synapse_type: The synapse to append\n",
    "    \"\"\"\n",
    "    # assert is_same_network(\n",
    "    #     pre, post\n",
    "    # ), \"Pre and post compartments must be part of the same network.\"\n",
    "    # assert np.all(\n",
    "    #     pre_comp_not_equal_post_comp(pre, post)\n",
    "    # ), \"Pre and post compartments must be different.\"\n",
    "\n",
    "    pre._append_multiple_synapses(pre, post, synapse_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1 recordings. See `.recordings` for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jnsbck/Uni/PhD/projects/jaxleyverse/jaxley/jaxley/utils/cell_utils.py:299: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_pathlens = pathlens / pathlens[-1]  # path lengths normalized to [0,1]\n"
     ]
    }
   ],
   "source": [
    "# Before: View would take a module and wrap its methods if needed. This meant:\n",
    "# 1. All methods meant to be accessed both in view and module had to be hidden\n",
    "#    and accessed via wrappers in either view or module. This was a lot of boilerplate.\n",
    "# 2. View was fundamentally a different object from module. This meant views only\n",
    "#    had access to a subset of module's methods and attributes. Hence, i.e. net.cell(0)\n",
    "#    did not support looking at all its attrs and could not be simulated on its own.\n",
    "# 3. Indexing global vs local and managing how things were viewed was a bit clunky.\n",
    "# ----------------------------\n",
    "# Now: View returns a Module instance of itself with a different indexes in view.\n",
    "# This means all methods in Module also work on View. The job of View now is to\n",
    "# manage how attributes are returned based on the indexes in view. This means:\n",
    "# calling View(module, inds) will behave like a module that only has a subset of\n",
    "# nodes, edges etc., as defined by inds.\n",
    "\n",
    "\n",
    "# Setup\n",
    "comp = jx.Compartment()\n",
    "branch = jx.Branch(comp, nseg=4)\n",
    "cell = jx.Cell(branch, parents=[-1, 0, 0, 1, 1, 2, 2])\n",
    "net = jx.Network([cell]*5)\n",
    "net = DummyModule(net) # like Module but with subset of attrs currently supported by the new view\n",
    "net.cell(0).insert(HH())\n",
    "\n",
    "# things that are working\n",
    "# connect\n",
    "connect(net.cell(0).branch(0).comp(0), net.cell(0).branch(1).comp(0), IonotropicSynapse())\n",
    "connect(net.cell(0).branch([1,2]).comp(0), net.cell(1).branch([3,4]).comp(0), TestSynapse())\n",
    "\n",
    "# mechanisms\n",
    "net.cell(\"all\").insert(HH())\n",
    "\n",
    "# recording\n",
    "net.cell(1).branch(0).comp(0).record(\"v\")\n",
    "\n",
    "# stimuli\n",
    "net.cell(0).branch(0).comp(0).stimulate(np.zeros((1, 10)))\n",
    "\n",
    "# clamping\n",
    "net.cell(0).branch([0,1]).comp(0).clamp(\"v\", np.ones((1, 10))*-65)\n",
    "\n",
    "# setting trainables\n",
    "net.cell(1).branch(0).comp(\"all\").make_trainable(\"HH_gNa\")\n",
    "# TODO: Treat Synapse trainables different?\n",
    "\n",
    "# NEW/OLD FEATURES\n",
    "# more flexible indexing / selection with at \n",
    "# (tracked via dataframe index, which does not change with scope)\n",
    "rnd_inds = np.random.randint(0, len(net.nodes),10)\n",
    "net.at(rnd_inds)\n",
    "\n",
    "# arbitrary selection\n",
    "net.branch(0).show()\n",
    "net.comp(0).show()\n",
    "\n",
    "# scope\n",
    "net.set_scope(\"global\")\n",
    "net.cell([0,2]).branch([0]).comp([1,2]).show() # -> [1,2] \n",
    "\n",
    "net.set_scope(\"local\")\n",
    "net.cell([0,2]).branch([0]).comp([1,2]).show() # -> [1,2,41,42]\n",
    "\n",
    "net.scope(\"local\").comp(0).show()\n",
    "# vs.\n",
    "net.scope(\"global\").comp(0).show()\n",
    "\n",
    "# context management\n",
    "with net.cell(0).branch(0).comp(0) as comp0:\n",
    "    comp0.set(\"v\", -70)\n",
    "    comp0.set(\"radius\", 0.1)\n",
    "net.cell(0).branch(0).comp([0,1]).show()[[\"v\", \"radius\"]]\n",
    "\n",
    "# iterables\n",
    "for cell in net.cells:\n",
    "    for branch in cell.branches:\n",
    "        for comp in branch.comps:\n",
    "            comp.set(\"v\", -71)\n",
    "\n",
    "for comp in net.cell(0).branch(0).comps:\n",
    "    comp.set(\"v\", -72)\n",
    "net.show()[[\"v\"]]\n",
    "\n",
    "# indexing\n",
    "net[0,0,0].show()\n",
    "\n",
    "# groups\n",
    "net.cell(1).branch(0).add_group(\"group\")\n",
    "net.group.show()\n",
    "\n",
    "# Channel and Synapse views\n",
    "net.HH.show()\n",
    "net.cell(0).HH.nodes\n",
    "net.HH.cell(0).nodes\n",
    "\n",
    "net.TestSynapse.nodes\n",
    "net.TestSynapse.cell(0).nodes\n",
    "net.cell([0,1]).TestSynapse.nodes\n",
    "\n",
    "# shape\n",
    "net.shape\n",
    "net.cell(0).shape\n",
    "\n",
    "# copying\n",
    "cell0 = net.cell(0).copy()\n",
    "cell0.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxley",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
