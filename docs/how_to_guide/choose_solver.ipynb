{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88166056",
   "metadata": {},
   "source": [
    "# How to choose a solver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663f52ba",
   "metadata": {},
   "source": [
    "`Jaxley` provides four different solvers for the differential equations: Backward Euler (`bwd_euler`, the default), Forward Euler (`fwd_euler`), Exponential Euler (`exp_euler`) and the Crank-Nicolson solver (`crank_nicolson`). The solver can be changed as follows:\n",
    "```python\n",
    "jx.integrate(..., solver=\"exp_euler\")\n",
    "```\n",
    "Which solver is best for which scenario?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f8b048",
   "metadata": {},
   "source": [
    "> **⚠️ IMPORTANT!**  \n",
    "> We try to be general here, but different morphologies and different hardware might lead to different conclusions. If you find that our advice is different from your experience, we would appreciate if you would let us know by [creating an issue on GitHub](https://github.com/jaxleyverse/jaxley/issues)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f182e9f",
   "metadata": {},
   "source": [
    "## Single-compartment model\n",
    "\n",
    "For single compartment neurons, all solvers should be relatively stable, give similar results, and have similar computational speed. We note that exponential Euler is not yet optimized for _network simulations_, and will be very slow for them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6752e566",
   "metadata": {},
   "source": [
    "## Multi-compartment models\n",
    "\n",
    "For multi-compartment models, the solver can have a big impact on accuracy and speed.\n",
    "\n",
    "### Forward Euler\n",
    "\n",
    "`fwd_euler` can be very efficient, but it will typically be unstable and explode. Avoid `fwd_euler` for multicompartment simulations.\n",
    "\n",
    "### Backward Euler and Crank Nicolson\n",
    "\n",
    "`bwd_euler` and `crank_nicolson` are numerically stable. On CPU, they are typically the most efficient solvers. On GPU, they can also be efficient, but you might get speed-ups with exponential Euler (see below).\n",
    "\n",
    "### Exponential Euler\n",
    "\n",
    "`exp_euler` is also numerically stable. On CPU, it will typically be signicantly _slower_ than `bwd_euler` or `crank_nicolson`. On GPU, you might be able to get speed-ups with `exp_euler`, even with default settings (in particular for small morphologies of <1000 compartments):\n",
    "```python\n",
    "v = jx.integrate(..., solver=\"exp_euler\")\n",
    "```\n",
    "\n",
    "If you run many simulations with the same `axial_resistivity`, `length`, `radius`, and `capacitance`, the `exp_euler` can give very large speedups _on GPU_ (~4-20 times faster than `bwd_euler` or `crank_nicolson`). To achieve this, precompute the transition matrix _once_ (before all of your simulations)\n",
    "```python\n",
    "cell.customize_solver_exp_euler(\n",
    "    exp_euler_transition=cell.build_exp_euler_transition_matrix(delta_t)\n",
    ")\n",
    "```\n",
    "and then run the integration loop (which will automatically detect that the transition matrix has been precomputed and will not compute it again):\n",
    "```python\n",
    "v1 = jx.integrate(cell, solver=\"exp_euler\")\n",
    "cell.set(\"gLeak\", 1e-4)\n",
    "v2 = jx.integrate(cell, solver=\"exp_euler\")\n",
    "```\n",
    "\n",
    "We note that exponential Euler is not yet optimized for _network simulations_, and can be very slow for them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxley",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
